{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция 8: Современные подходы в машинном обучении"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой лекции будут обзорно рассмотрены актуальные темы, которые могут встретиться в литературе или на конференциях.\n",
    "\n",
    "- Рассмотрим альтернативный подход для использования нейронных сетей - графовые нейросети;\n",
    "- Обсудим интерпретируемость моделей и инструменты для этого;\n",
    "- Обучение с подкреплением как самую часто возникающую тему при реализации моделей в проде или проведении симуляций\n",
    "- AutoML в качестве высокоуровнего подхода к использованию моделей\n",
    "- Диффузионные модели - основной инструмент для решения задач генерации изображений и видео."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Графовые нейросети (Graph Neural Networks, GNN)\n",
    "\n",
    "Графовые нейросети предназначены для обработки данных, представленных в виде графов, где вершины – объекты, а ребра – их взаимосвязи. Такие модели находят применение в:\n",
    "- социальных сетях, \n",
    "- биоинформатике и химии в целом, \n",
    "- рекомендационных системах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание\n",
    "\n",
    "Рассмотрим граф $ G = (V, E) $, где:\n",
    "- $ V = \\{v_1, v_2, \\dots, v_n\\} $ — множество вершин (узлов).\n",
    "- $ E \\subseteq V \\times V $ — множество рёбер (связей) между узлами.\n",
    "\n",
    "Каждая вершина $ v_i $ имеет вектор признаков $ \\mathbf{x}_i \\in \\mathbb{R}^d $ (например, текст, атрибуты, числовые показатели - любые идентифицирующие вершину параметры). Все признаки можно собрать в матрицу:\n",
    "$$\n",
    "X \\in \\mathbb{R}^{n \\times d}\n",
    "$$\n",
    "Связи между вершинами описываются матрицей смежности:\n",
    "$$\n",
    "A \\in \\mathbb{R}^{n \\times n}, \\quad \\text{где } A_{ij} = \\begin{cases} 1, & \\text{если есть ребро между } v_i \\text{ и } v_j \\\\ 0, & \\text{иначе} \\end{cases}\n",
    "$$\n",
    "\n",
    "Одним из классических вариантов GNN является **GCN** (Graph Convolutional Network), предложенный Kipf & Welling (2016). Основная идея слоя GCN заключается в агрегации признаков соседей и обновлении представления узлов. На каждом шаге все вершины отправляют сообщения своим соседям, после чего обновляют свое состояние в соответствии с полученными новыми сообщениями - Message Passing.\n",
    "\n",
    "#### Алгоритм работы одного слоя GCN:\n",
    "1. **Агрегация:** Для каждой вершины собрать признаки её соседей (среднее, максимум, RNN и другие).\n",
    "2. **Линейное преобразование:** Применить обучаемую матрицу весов.\n",
    "3. **Нелинейность:** Пропустить результат через функцию активации.\n",
    "\n",
    "При использовании множества слоев возникает проблема размытия - Over-smoothing. На ребра могут быть добавлены веса.\n",
    "\n",
    "#### Математическая формулировка\n",
    "Для слоя $ l $, в случае использования нормализации, обновление признаков записывается так:\n",
    "$$\n",
    "H^{(l+1)} = \\sigma\\left(\\tilde{D}^{-1/2} \\tilde{A} \\tilde{D}^{-1/2} H^{(l)} W^{(l)}\\right)\n",
    "$$\n",
    "где:\n",
    "- $ H^{(l)} \\in \\mathbb{R}^{n \\times d_l} $ — матрица признаков на $ l $-ом слое ($ H^{(0)} = X $).\n",
    "- $\\tilde{A} = A + I$ — матрица смежности с добавлением самосвязей (единичная матрица $ I $ добавляется для учета собственного узла).\n",
    "- $\\tilde{D}$ — диагональная матрица, где $ \\tilde{D}_{ii} = \\sum_j \\tilde{A}_{ij} $. Показывает количество связей для каждой вершины.\n",
    "- $ W^{(l)} $ — матрица весов $ l $-го слоя.\n",
    "- $\\sigma(\\cdot)$ — нелинейная функция активации.\n",
    "\n",
    "**Пояснения:**\n",
    "- Матрица смежности графа - квадратная матрица из нулей и единиц размера $ n \\times n $, где единицы в стоят в позициях свеянных между собой вершин.\n",
    "- Матрица $\\tilde{D}$ делает нормализацию.\n",
    "\n",
    "Кроме того, есть альтернативный вариант - использование Attention.\n",
    "\n",
    "**Алгоритм:**\n",
    "- Для каждой пары (для каждого из соседей определенного ребра) объединяем вектора признаков в один вектор.\n",
    "- Применяем к нему линейный слой, функцию активации и Softmax.\n",
    "- полученные значения используются в качестве дополнительных весов при аналогичной предыдущей реализации свертки.\n",
    "\n",
    "Такой подход позволяет каждому узлу учитывать информацию от соседей, а нормировка через $\\tilde{D}^{-1/2}$ помогает избежать числовых нестабильностей при работе с разреженными матрицами смежности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример\n",
    "\n",
    "Библиотеки, такие как [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/) и [DGL](https://www.dgl.ai/), позволяют быстро создавать и обучать GNN.\n",
    "\n",
    "Для практической демонстрации воспользуемся классическим датасетом **Cora**:\n",
    "- В датасете [Cora](https://paperswithcode.com/dataset/cora) содержится 2708 научных публикаций (узлов), 5429 ссылок между ними (рёбер) и 7 категорий (тематика публикаций).\n",
    "- Cora широко используется для тестирования методов классификации на графах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch_geometric -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Загрузка датасета Cora\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "# Преобразуем данные в граф NetworkX для визуализации.\n",
    "# Для наглядности берем подграф из первых 100 узлов.\n",
    "edge_index = data.edge_index.numpy()\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edge_index.T)\n",
    "sub_nodes = list(G.nodes())[:100]\n",
    "subG = G.subgraph(sub_nodes)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "nx.draw(subG, with_labels=True, node_size=300, font_size=8)\n",
    "plt.title(\"Подграф датасета Cora (100 узлов)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = GCN(dataset.num_features, 16, dataset.num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits, accs = model(data), []\n",
    "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "for epoch in range(200+1):\n",
    "    loss = train()\n",
    "    train_acc, val_acc, test_acc = test()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch {epoch:03d} Loss: {loss:.4f} Train: {train_acc:.4f} Val: {val_acc:.4f} Test: {test_acc:.4f}')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = model.conv1(data.x, data.edge_index)\n",
    "    embeddings = F.relu(embeddings)\n",
    "\n",
    "embeddings_2d = TSNE(n_components=2).fit_transform(embeddings.cpu().numpy())\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=data.y.cpu().numpy(), cmap=\"jet\", s=15)\n",
    "plt.title(\"t-SNE визуализация встраиваний узлов (GCN)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Интерпретируемость моделей (Explainable AI, XAI)\n",
    "\n",
    "Методы интерпретируемости помогают понять, почему модель принимает те или иные решения. Это особенно важно для критичных областей (медицина, финансы). Популярные подходы включают:\n",
    "- **SHAP (SHapley Additive exPlanations)**\n",
    "- **LIME (Local Interpretable Model-agnostic Explanations)**\n",
    "- **Integrated Gradients**\n",
    "- **Attention maps**\n",
    "\n",
    "### Стандартный подход\n",
    "Например, градиентный спуск на каждой итерации делает какое-то разбиение, пусти нас интересуют все разбиения сделанные по какому-либо определенному признаку. Каждое такое разбиение дает уменьшение функции потерь, их сумма дает суммарный выигрыш по определенному признаку - Gain. Однако такой подсчет может быть неверным.\n",
    "\n",
    "### SHAP (SHapley Additive exPlanations)\n",
    "\n",
    "Первоначальная идея: спрячем один из признаков от модели и обучим ее снова - предсказание изменится. Величина изменения - это вклад признака. Делаем так с остальными. Получается очень дорого... \n",
    "\n",
    "Поэтому сделаем иначе:\n",
    "\n",
    "Метод основан на концепции shapley-value из теории кооперативных игр. Каждый признак рассматривается как «игрок», вносящий вклад в итоговое предсказание модели. SHAP распределяет эффект модели на отдельные признаки так, что сумма вкладов равна разнице между прогнозом для данного наблюдения и базовым (средним) прогнозом.\n",
    "\n",
    "Для модели $ f $ и наблюдения $ x $ предсказание раскладывается так:  \n",
    "$$\n",
    "f(x) = \\phi_0 + \\sum_{i=1}^{M} \\phi_i\n",
    "$$\n",
    "где:\n",
    "- $ \\phi_0 $ – базовое значение (например, среднее по выборке),\n",
    "- $ \\phi_i $ – вклад $ i $-го признака, вычисляемый по формуле shapley-value:\n",
    "$$\n",
    "\\phi_i = \\sum_{S \\subseteq F \\setminus \\{i\\}} \\frac{|S|!(|F|-|S|-1)!}{|F|!} \\Bigl( f_{S \\cup \\{i\\}}(x_{S \\cup \\{i\\}}) - f_S(x_S) \\Bigr)\n",
    "$$\n",
    "При этом: \n",
    "- $ F $ – множество всех признаков. Мы рассматриваем все возможные подмножества признаков, которые **не содержат** признак $ i $.\n",
    "- $ S $ – подмножество признаков,\n",
    "- $ f_S $ – модель, обученная или оцененная только на признаках из $ S $.\n",
    "\n",
    "Разберем эту формулу:\n",
    "- Справа: смотрим ошибку алгоритма с признаком и без него (насколько изменится ответ без использования признака).\n",
    "- Слева: комбинаторный вес, который учитывает количество возможных порядков (перестановок) признаков. Он гарантирует, что вклад каждого признака будет усреднён по всем возможным порядкам их включения в модель.\n",
    "\n",
    "**Особенности:**\n",
    "- Гарантирует локальную точность (сумма вкладов точно объясняет разницу в предсказании).\n",
    "- Обеспечивает консистентность при изменении модели.\n",
    "\n",
    "#### LIME (Local Interpretable Model-agnostic Explanations)\n",
    " \n",
    "LIME строит интерпретируемую локальную аппроксимацию сложной модели вокруг конкретного наблюдения. Для этого генерируются искусственные примеры путём незначительных изменений исходного входа, после чего на этих данных обучается простая модель (например, линейная регрессия).\n",
    "\n",
    "**Особенности:**\n",
    "- Метод «локален»: объяснение действительно только в окрестности конкретного примера.\n",
    "- Универсален: применим к любым моделям, так как не требует внутреннего устройства.\n",
    "\n",
    "#### Integrated Gradients\n",
    "\n",
    "Этот метод применяется для глубоких нейросетей. Он вычисляет вклад каждого признака, интегрируя градиенты вдоль прямой линии от базового (обычно нулевого) входа до фактического входа $ x $.\n",
    "\n",
    "Для признака $ i $ вклад определяется как:\n",
    "$$\n",
    "IG_i(x) = (x_i - x_i') \\times \\int_{\\alpha=0}^{1} \\frac{\\partial f\\bigl(x' + \\alpha (x - x')\\bigr)}{\\partial x_i} d\\alpha\n",
    "$$\n",
    "где $ x' $ – базовый вход, а $ f $ – модель. Этот метод обладает свойствами чувствительности и инвариантности к реализации.\n",
    "\n",
    "#### Attention maps\n",
    "\n",
    "Attention maps используются в моделях с механизмом внимания (например, в трансформерах). Они визуализируют весовые коэффициенты, показывая, на какие части входа модель обращает больше внимания при формировании предсказания.\n",
    "\n",
    "**Особенности:**\n",
    "- В NLP: внимание между токенами предложения.\n",
    "- В компьютерном зрении: внимание к различным областям изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример\n",
    "\n",
    "В качестве примера выберем датасет **Breast Cancer** из библиотеки scikit-learn, обладающий понятными и интерпретируемыми признаками (например, «mean radius», «mean texture», и т.д.). Для модели воспользуемся классификатором XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y,\n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)\n",
    "\n",
    "model = xgb.XGBClassifier(n_estimators=100, \n",
    "                          learning_rate=0.1, \n",
    "                          importance_type=\"weight\", \n",
    "                          random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install shap -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "features = data.feature_names\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(features, importances)\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Важность признаков по XGBoost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **SHAP:** Дает детальную локальную интерпретацию для каждого наблюдения, позволяет увидеть, как признаки влияют на конкретное предсказание, и учитывает взаимодействие признаков.  \n",
    "- **Feature Importance:** Предоставляет глобальную оценку важности признаков, не раскрывая, как именно они влияют на отдельные прогнозы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning (Обучение с подкреплением)\n",
    "\n",
    "Обучение с подкреплением (RL) – это подход, при котором агент (модель) обучается взаимодействовать со средой, получая обратную связь в виде вознаграждения. Основная цель – найти такую стратегию (policy), которая максимизирует суммарное вознаграждение. \n",
    "\n",
    "RL применяется в играх, робототехнике, управлении и оптимизации процессов.\n",
    "\n",
    "Лекции: \n",
    "- [Воронцов](https://www.youtube.com/watch?v=iEUrX_eEWNY&t=499s&ab_channel=YandexforML)\n",
    "- [Нейчев](https://www.youtube.com/watch?v=neYEP75m4bo&ab_channel=%D0%9B%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%B8%D0%B9%D0%A4%D0%9F%D0%9C%D0%98)\n",
    "\n",
    "### Терминология\n",
    "- **Агент:** обучаемая система, принимающая решения.\n",
    "- **Среда (Environment):** внешний мир, с которым взаимодействует агент.\n",
    "- **Состояние (State, $s$):** описание среды в конкретный момент времени.\n",
    "- **Действие (Action, $a$):** выбор агента, влияющий на состояние среды.\n",
    "- **Вознаграждение (Reward, $r$):** числовая оценка качества выбранного действия.\n",
    "- **Политика (Policy, $\\pi(a|s)$):** стратегия выбора действий на основе текущего состояния.\n",
    "- **Функция ценности (Value Function):** оценка качества состояния или пары состояние-действие (например, $V(s)$ или $Q(s,a)$).\n",
    "- **Преимущество (Advantage, $\\hat{A}(s,a)$):** разница между фактическим вознаграждением и ожидаемой ценностью, помогает понять, насколько лучше (или хуже) действие по сравнению со средним.\n",
    "\n",
    "### Основные стадии обучения\n",
    "1. **Сбор опыта:** Агент взаимодействует со средой, собирая переходы: $(s_t, a_t, r_t, s_{t+1})$.\n",
    "2. **Оценка политики:** На основе собранных данных вычисляются значения функции ценности и преимущества.\n",
    "3. **Обновление политики:** Используя методы градиентного спуска, политика корректируется так, чтобы увеличить вероятность выбора действий, приносящих высокое вознаграждение.\n",
    "4. **Баланс между исследованием и эксплуатацией:** Агент должен исследовать новые действия (exploration) и использовать уже известные (exploitation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание ключевых алгоритмов\n",
    "\n",
    "#### Proximal Policy Optimization (PPO)\n",
    "\n",
    "PPO – один из самых популярных алгоритмов, сочетающий стабильность и эффективность. Основная идея – ограничить изменение политики на каждом шаге, чтобы избежать чрезмерных обновлений.\n",
    "\n",
    "Для старой политики $\\pi_{\\theta_{\\text{old}}}$ и новой $\\pi_{\\theta}$ определяется отношение:\n",
    "$$\n",
    "r_t(\\theta) = \\frac{\\pi_{\\theta}(a_t|s_t)}{\\pi_{\\theta_{\\text{old}}}(a_t|s_t)}\n",
    "$$\n",
    "Объективная функция с использованием механизма обрезки (clipping):\n",
    "$$\n",
    "L^{\\text{CLIP}}(\\theta) = \\hat{\\mathbb{E}}_t \\left[\\min\\Bigl( r_t(\\theta)\\,\\hat{A}_t,\\; \\text{clip}\\bigl(r_t(\\theta),1-\\epsilon,1+\\epsilon\\bigr)\\,\\hat{A}_t \\Bigr) \\right]\n",
    "$$\n",
    "где:\n",
    "- $\\hat{A}_t$ – оценка преимущества.\n",
    "- $\\epsilon$ – параметр, определяющий допустимое отклонение от старой политики (обычно $0.1 \\dots 0.3$).\n",
    "\n",
    "Этот метод гарантирует, что обновление политики не приведёт к слишком резкому изменению, что делает обучение более стабильным.\n",
    "\n",
    "#### Direct Preference Optimization (DPO)\n",
    "\n",
    "DPO – относительно новый подход, часто используемый в контексте обучения с человеческой обратной связью (например, в RLHF). Вместо явного определения функции вознаграждения, DPO использует парные предпочтения, чтобы оптимизировать политику.\n",
    "\n",
    "**RLHF (Reinforcement Learning from Human Feedback)** – это подход, при котором обучение модели осуществляется с использованием сигналов, предоставляемых человеком. Обычно сначала обучается базовая модель, затем собирается обратная связь (например, предпочтения или оценки) от пользователей, и на основе этой информации дообучается политика (часто с использованием методов, подобных DPO). Такой подход позволяет сделать модель более соответствующей ожиданиям и ценностям конечных пользователей.\n",
    "\n",
    "Для пары предпочтительных действий $a^+$ (предпочтительный) и $a^-$ (непредпочтительный) в одном и том же состоянии $s$, DPO стремится оптимизировать такую функцию потерь:\n",
    "$$\n",
    "L(\\theta) = -\\mathbb{E}_{(s,a^+,a^-)} \\log \\frac{\\exp\\bigl(\\beta \\log \\pi_\\theta(a^+|s)\\bigr)}{\\exp\\bigl(\\beta \\log \\pi_\\theta(a^+|s)\\bigr) + \\exp\\bigl(\\beta \\log \\pi_\\theta(a^-|s)\\bigr)}\n",
    "$$\n",
    "где:\n",
    "- $\\pi_\\theta(a|s)$ – политика с параметрами $\\theta$.\n",
    "- $\\beta$ – параметр масштаба, регулирующий чувствительность к разнице между лог-вероятностями.\n",
    "\n",
    "Таким образом, модель обучается так, чтобы вероятность выбора предпочтительного действия была выше, чем вероятность выбора непредпочтительного.\n",
    "\n",
    "#### Другие алгоритмы\n",
    "\n",
    "- **DQN (Deep Q-Network):** Использует нейросеть для аппроксимации Q-функции $Q(s,a)$. Обновление происходит через минимизацию ошибки между целевым и текущим Q-значением.\n",
    "- **A3C (Asynchronous Advantage Actor-Critic):** Параллельно обучает несколько агентов, что позволяет ускорить сбор опыта и уменьшить корреляцию между наблюдениями.\n",
    "- **SAC (Soft Actor-Critic):** Алгоритм, оптимизирующий энтропийное регуляризированное вознаграждение, что приводит к более устойчивому исследованию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример с использованием [задачи](https://www.gymlibrary.dev/environments/classic_control/cart_pole/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gym stable_baselines3 shimmy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "total_timesteps = 20000\n",
    "model.learn(total_timesteps=total_timesteps)\n",
    "\n",
    "episodes = 20\n",
    "episode_rewards = []\n",
    "\n",
    "for episode in range(episodes):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "    episode_rewards.append(total_reward)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, episodes+1), episode_rewards, marker='o')\n",
    "plt.title(\"Вознаграждения агента в задаче CartPole\")\n",
    "plt.xlabel(\"Эпизод\")\n",
    "plt.ylabel(\"Суммарное вознаграждение\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML\n",
    "\n",
    "AutoML (Automated Machine Learning) – это набор методов и инструментов, направленных на автоматизацию всего процесса создания модели машинного обучения. \n",
    "\n",
    "Это включает:\n",
    "- **Предобработку данных:** автоматический выбор и применение методов очистки, нормализации, отбора признаков и создания новых признаков.\n",
    "- **Выбор модели:** определение наиболее подходящих алгоритмов для конкретной задачи (например, деревья решений, градиентный бустинг, SVM и др.).\n",
    "- **Тюнинг гиперпараметров:** поиск оптимальных значений гиперпараметров моделей с использованием методов, таких как случайный поиск, байесовская оптимизация, эволюционные алгоритмы и т.д.\n",
    "- **Сборка пайплайна:** комбинирование этапов предобработки, выбора модели и тюнинга в единую автоматизированную систему.\n",
    "- **Ансамблирование:** объединение нескольких моделей для повышения качества предсказаний.\n",
    "\n",
    "Существуют инструменты, такие как [auto-sklearn](https://automl.github.io/auto-sklearn/master/) или [TPOT](http://epistasislab.github.io/tpot/), которые помогают быстро найти оптимальное решение для задачи без глубоких знаний в ML.\n",
    "\n",
    "### Как работает AutoML?\n",
    "\n",
    "1. **Определение пространства поиска:**\n",
    "   AutoML-фреймворки формируют множество возможных решений (пайплайнов) с различными комбинациями алгоритмов, методов предобработки и наборов гиперпараметров.\n",
    "\n",
    "2. **Поисковые алгоритмы:**\n",
    "   Для исследования пространства решений применяются:\n",
    "   - Случайный поиск – простое, но не всегда эффективное.\n",
    "   - Байесовская оптимизация – использование апостериорного распределения для целевой функции.\n",
    "   - Эволюционные алгоритмы – имитация естественного отбора для эволюции пайплайнов.\n",
    "   - Методы на основе градиентного спуска – для некоторых непрерывных параметров.\n",
    "\n",
    "3. **Кросс-валидация и метрики:**  \n",
    "   Каждая комбинация оценивается с использованием кросс-валидации, чтобы получить надежную оценку качества модели.\n",
    "\n",
    "4. **Ансамблирование:**  \n",
    "   После поиска лучших моделей часто строится ансамбль, в котором взвешиваются отдельные модели для получения более стабильного результата.\n",
    "\n",
    "### Плюсы и минусы\n",
    "\n",
    "**Плюсы:**\n",
    "- Автоматизация: позволяет значительно сократить время и усилия, требуемые для экспериментов с моделями.\n",
    "- Доступность: пользователи без глубоких знаний в ML могут получить конкурентоспособные модели.\n",
    "- Эффективность: часто находит нестандартные комбинации предобработки и моделей, которые сложно подобрать вручную.\n",
    "- Ансамблирование: встроенные методы ансамблирования могут повышать качество предсказаний.\n",
    "\n",
    "**Минусы:**\n",
    "- Вычислительные затраты: поиск по большому пространству гиперпараметров может требовать значительных вычислительных ресурсов.\n",
    "- Черный ящик: конечный пайплайн может быть сложным для интерпретации, что снижает прозрачность.\n",
    "- Ограничения по кастомизации: автоматизированные решения не всегда могут удовлетворить специфическим требованиям задачи.\n",
    "- Время обучения: полный поиск может занять много времени, особенно на больших датасетах.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример с использованием AutoML для sklearn (linux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install auto-sklearn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import autosklearn.classification\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=120,\n",
    "    per_run_time_limit=30\n",
    ")\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "print(automl.sprint_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = automl.cv_results_\n",
    "mean_scores = cv_results['mean_test_score']\n",
    "pipeline_indices = range(len(mean_scores))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(pipeline_indices, mean_scores, color='skyblue')\n",
    "plt.xlabel('Индекс пайплайна')\n",
    "plt.ylabel('CV Score')\n",
    "plt.title('Кросс-валидационные оценки для различных пайплайнов')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_with_weights = automl.get_models_with_weights()\n",
    "\n",
    "model_names = [type(model).__name__ for weight, model in models_with_weights]\n",
    "model_weights = [weight for weight, model in models_with_weights]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(model_names, model_weights, color='lightgreen')\n",
    "plt.xlabel(\"Тип модели\")\n",
    "plt.ylabel(\"Вес в ансамбле\")\n",
    "plt.title(\"Состав ансамбля, построенного AutoML\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = automl.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Точность на тестовой выборке:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Диффузионные модели\n",
    "\n",
    "Диффузионные модели – это класс генеративных моделей, в основе которых лежит процесс постепенного добавления шума к данным (прямой процесс) и последующее восстановление исходных данных через обратный процесс. Такие модели успешно применяются для генерации изображений, аудио и других типов данных.\n",
    "\n",
    "### Математическое описание\n",
    "\n",
    "#### Прямой (forward) процесс\n",
    "\n",
    "Пусть $ x_0 $ — исходное изображение или данные. Прямой процесс заключается в последовательном добавлении шума на каждом из $ T $ шагов. На шаге $ t $ процесс определяется следующим образом:\n",
    "\n",
    "$$\n",
    "q(x_t \\mid x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1-\\beta_t}\\, x_{t-1},\\, \\beta_t \\mathbf{I})\n",
    "$$\n",
    "\n",
    "где:\n",
    "- $ \\beta_t $ — коэффициент шума на шаге $ t $ (обычно выбирается небольшой, например, в диапазоне $ [10^{-4}, 0.02] $),\n",
    "- $ \\mathbf{I} $ — единичная матрица.\n",
    "\n",
    "Из-за свойств марковской цепи можно записать распределение на любом шаге $ t $ напрямую от $ x_0 $:\n",
    "\n",
    "$$\n",
    "q(x_t \\mid x_0) = \\mathcal{N}\\!\\Bigl(x_t; \\sqrt{\\bar{\\alpha}_t}\\, x_0,\\,(1-\\bar{\\alpha}_t)\\mathbf{I}\\Bigr)\n",
    "$$\n",
    "где:\n",
    "$$\n",
    "\\alpha_t = 1 - \\beta_t,\\quad \\bar{\\alpha}_t = \\prod_{s=1}^{t} \\alpha_s.\n",
    "$$\n",
    "\n",
    "#### Обратный (reverse) процесс\n",
    "\n",
    "Цель генеративной модели – восстановить $ x_0 $ из чистого шума $ x_T \\sim \\mathcal{N}(0,\\mathbf{I}) $ посредством обратного процесса. Этот процесс аппроксимируется с помощью нейросети с параметрами $ \\theta $:\n",
    "\n",
    "$$\n",
    "p_\\theta(x_{t-1} \\mid x_t) = \\mathcal{N}\\!\\Bigl(x_{t-1};\\, \\mu_\\theta(x_t, t),\\, \\Sigma_\\theta(x_t, t)\\Bigr).\n",
    "$$\n",
    "\n",
    "Обучение модели часто проводится с использованием упрощённой целевой функции, называемой _noise prediction objective_. Суть её в том, чтобы предсказать добавленный шум $\\epsilon$ в ходе прямого процесса:\n",
    "\n",
    "$$\n",
    "L_{\\text{simple}} = \\mathbb{E}_{x_0,\\, \\epsilon,\\, t}\\!\\Bigl[\\bigl\\|\\epsilon - \\epsilon_\\theta\\bigl(\\sqrt{\\bar{\\alpha}_t}\\, x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\, \\epsilon,\\ t\\bigr)\\bigr\\|^2\\Bigr],\n",
    "$$\n",
    "\n",
    "где:\n",
    "- $ \\epsilon \\sim \\mathcal{N}(0, \\mathbf{I}) $ – случайный шум,\n",
    "- $ \\epsilon_\\theta(x_t, t) $ – предсказание модели шума на шаге $ t $.\n",
    "\n",
    "### Процесс генерации\n",
    "\n",
    "После обучения генерация нового примера происходит итеративно:\n",
    "1. Начинаем с $ x_T \\sim \\mathcal{N}(0,\\mathbf{I}) $.\n",
    "2. Для каждого шага $ t $ от $ T $ до $ 1 $ выбираем:\n",
    "   $$\n",
    "   x_{t-1} \\sim p_\\theta(x_{t-1}\\mid x_t).\n",
    "   $$\n",
    "3. Итоговый $ x_0 $ – это сгенерированное изображение или данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Архитектура диффузионных моделей\n",
    "\n",
    "### U-Net\n",
    "\n",
    "Большинство современных диффузионных моделей используют **U-Net** архитектуру для предсказания шума $\\epsilon_\\theta(x_t, t)$. Ключевые элементы:\n",
    "- **Encoder:** Последовательность свёрточных слоёв, уменьшающих размерность, чтобы зафиксировать глобальные особенности.\n",
    "- **Decoder:** Последовательность свёрточных слоёв, увеличивающих размерность для восстановления исходного изображения.\n",
    "- **Skip connections:** Пропускные связи между соответствующими слоями encoder и decoder для сохранения деталей.\n",
    "- **Positional / Temporal Embeddings:** Кодирование номера шага $ t $ для информирования сети о текущей степени зашумлённости.\n",
    "\n",
    "### Дополнительные архитектурные решения\n",
    "\n",
    "- **Attention Mechanisms:** Включение слоёв внимания для захвата длиннозависимых зависимостей (например, в Stable Diffusion используется cross-attention для интеграции текстовых подсказок).\n",
    "- **Variational Autoencoder (VAE):** В некоторых моделях, таких как Stable Diffusion, используется VAE для кодирования изображений в более компактное латентное пространство перед применением диффузионного процесса.\n",
    "\n",
    "### Построение модели с нуля\n",
    "\n",
    "Чтобы реализовать диффузионную модель с нуля:\n",
    "1. **Определить прямой процесс:** Выбрать схему $ \\beta_t $ для добавления шума.\n",
    "2. **Построить U-Net:** Реализовать U-Net, принимающий на вход зашумлённое изображение $ x_t $ и временной индекс $ t $ (с эмбеддингом).\n",
    "3. **Функция потерь:** Определить loss-функцию $ L_{\\text{simple}} $ для обучения модели предсказывать шум.\n",
    "4. **Обучение:** Обучать сеть на датасете изображений, постепенно уменьшая шум.\n",
    "5. **Генерация:** Реализовать обратный процесс, начиная с $ x_T \\sim \\mathcal{N}(0, \\mathbf{I}) $ и восстанавливая $ x_0 $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Практический пример с использованием готовой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install diffusers accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)\n",
    "\n",
    "prompt = \"A surreal landscape with vivid colors, intricate details, and a dreamlike atmosphere\"\n",
    "result = pipe(prompt)\n",
    "image = result.images[0]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Сгенерированное изображение с помощью Stable Diffusion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Процесса работы\n",
    "\n",
    "- **Энкодер текста:** Входной текст обрабатывается текстовым энкодером (например, CLIP) для получения условного представления.\n",
    "- **Латентное пространство:** Изображение кодируется в компактное латентное пространство с помощью VAE.\n",
    "- **Обратный диффузионный процесс:** U-Net принимает на вход зашумлённое латентное представление и временной индекс $ t $ (с дополнительными эмбеддингами) и предсказывает шум, постепенно приближая латентное представление к \"чистому\" изображению.\n",
    "- **Декодирование:** После обратного процесса латентное представление преобразуется в изображение через VAE-декодер.\n",
    "- **Архитектура:** Модель включает U-Net с вниманием, слои нормализации и позиционные эмбеддинги, что позволяет точно управлять процессом восстановления изображения."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
