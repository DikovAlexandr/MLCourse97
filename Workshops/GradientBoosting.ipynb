{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "organized-tension",
   "metadata": {
    "id": "organized-tension"
   },
   "source": [
    "# Бэггинг и градиентный бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-modem",
   "metadata": {
    "id": "shared-modem"
   },
   "source": [
    "## Бэггинг и градиентный бустинг.\n",
    "\n",
    "Давайте проанализируем, как производительность бэггинга и градиентного бустинга зависит от количества базовых элементов в ансамбле.\n",
    "\n",
    "В случае бэггинга все базовые модели подгоняются под разные выборки из одного и того же распределения данных $\\mathbb{X} \\times \\mathbb{Y}$. Некоторые из них могут быть переобучены, тем не менее, последующее усреднение их предсказаний позволяет смягчить этот эффект. \n",
    "\n",
    "Причина этого в том, что для некоррелированных алгоритмов дисперсия их композиции в $N$ раз ниже индивидуальной. Другими словами, крайне маловероятно, что все компоненты ансамбля переобучаются под какой-то нетипичный объект из обучающего набора (по сравнению с одной моделью). Когда размер ансамбля $N$ становится достаточно большим, дальнейшее добавление базовых моделей не увеличивает качество.\n",
    "\n",
    "При бустинге каждый алгоритм подгоняется под ошибки текущей построенной композиции, что позволяет ансамблю постепенно улучшать качество аппроксимации распределения данных. Однако увеличение размера ансамбля $N$ может привести к переобучению, поскольку добавление новых моделей в композицию еще больше соответствует обучающим данным и в конечном итоге может снизить способность к обобщению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rough-mumbai",
   "metadata": {
    "id": "rough-mumbai"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-dialogue",
   "metadata": {
    "id": "noticed-dialogue",
    "outputId": "f234e332-3eac-4307-ab7c-6251cc7597cd"
   },
   "outputs": [],
   "source": [
    "X_train = np.linspace(0, 1, 100)\n",
    "X_test = np.linspace(0, 1, 1000)\n",
    "\n",
    "@np.vectorize\n",
    "def target(x):\n",
    "    return x > 0.5\n",
    "\n",
    "Y_train = target(X_train) + np.random.randn(*X_train.shape) * 0.1\n",
    "\n",
    "plt.figure(figsize = (8, 6))\n",
    "plt.scatter(X_train, Y_train, s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-advice",
   "metadata": {
    "id": "rational-advice"
   },
   "source": [
    "Для начала возьмем алгоритм бэггинга на деревьях решений.\n",
    "\n",
    "Здесь размер ансамбля постепенно увеличивается.\n",
    "Давайте посмотрим, как прогноз зависит от размера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-pillow",
   "metadata": {
    "id": "organic-pillow",
    "outputId": "67bbd381-40ad-4729-fbcc-ae0680d36caa"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor\n",
    "\n",
    "reg = BaggingRegressor(DecisionTreeRegressor(max_depth=2), warm_start=True)\n",
    "plt.figure(figsize=(15, 12))\n",
    "sizes = [1, 2, 5, 20, 100, 500, 1000, 2000]\n",
    "for i, s in enumerate(sizes):\n",
    "    reg.n_estimators = s\n",
    "    reg.fit(X_train.reshape(-1, 1), Y_train)\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.xlim([0, 1])\n",
    "    plt.scatter(X_train, Y_train, s=10)\n",
    "    plt.plot(X_test, reg.predict(X_test.reshape(-1, 1)), c='green', linewidth=2)\n",
    "    plt.title('{} trees'.format(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-watts",
   "metadata": {
    "id": "everyday-watts"
   },
   "source": [
    "Можете видеть, что после определенного момента общий прогноз не меняется при добавлении базовых моделей.\n",
    "\n",
    "Теперь давайте сделаем то же самое с градиентным бустингом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-latest",
   "metadata": {
    "id": "honey-latest",
    "outputId": "a2ce7ebc-c03b-4a91-f1f7-604255530190"
   },
   "outputs": [],
   "source": [
    "reg = GradientBoostingRegressor(max_depth=1, learning_rate=1, warm_start=True)\n",
    "plt.figure(figsize=(15, 12))\n",
    "sizes = [1, 2, 5, 20, 100, 500, 1000, 2000]\n",
    "for i, s in enumerate(sizes):\n",
    "    reg.n_estimators = s\n",
    "    reg.fit(X_train.reshape(-1, 1), Y_train)\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.xlim([0, 1])\n",
    "    plt.scatter(X_train, Y_train, s=10)\n",
    "    plt.plot(X_test, reg.predict(X_test.reshape(-1, 1)), c='green', linewidth=2)\n",
    "    plt.title('{} trees'.format(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-refrigerator",
   "metadata": {
    "id": "administrative-refrigerator"
   },
   "source": [
    "Градиентный бустинг быстро улавливает истинную зависимость, но затем начинает переобучение по отношению к отдельным объектам из обучающего набора. В результате модели с большими размерами ансамбля оказываются сильно переобученными.\n",
    "\n",
    "Можно решить эту проблему, выбрав очень простую базовый модель или намеренно снизив вес последующих алгоритмов в композиции:\n",
    "$$\n",
    "a_N(x) = \\sum_{n=0}^N \\eta \\gamma_N b_n(x).\n",
    "$$\n",
    "\n",
    "Здесь $\\eta$ — это параметр шага, который контролирует влияние новых компонентов ансамбля.\n",
    "\n",
    "Такой подход делает обучение медленнее по сравнению с бэггингом, однако делает конечную модель менее переобученной. Тем не менее следует помнить, что переобучение может произойти для любого $\\eta$ в пределе бесконечного размера ансамбля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-castle",
   "metadata": {
    "id": "thousand-castle",
    "outputId": "854517bd-8659-4de2-a0fc-8f8d97a0729e"
   },
   "outputs": [],
   "source": [
    "reg = GradientBoostingRegressor(max_depth=1, learning_rate=0.1, warm_start=True)\n",
    "plt.figure(figsize=(15, 12))\n",
    "sizes = [1, 2, 5, 20, 100, 500, 1000, 2000]\n",
    "for i, s in enumerate(sizes):\n",
    "    reg.n_estimators = s\n",
    "    reg.fit(X_train.reshape(-1, 1), Y_train)\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.xlim([0, 1])\n",
    "    plt.scatter(X_train, Y_train, s=10)\n",
    "    plt.plot(X_test, reg.predict(X_test.reshape(-1, 1)), c='green', linewidth=2)\n",
    "    plt.title('{} trees'.format(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-relevance",
   "metadata": {
    "id": "verified-relevance"
   },
   "source": [
    "Давайте рассмотрим описанное явление на более реалистичном наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "respected-hindu",
   "metadata": {
    "id": "respected-hindu",
    "outputId": "fa04b09e-3453-456c-e35d-fcb348615632"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ds = datasets.load_diabetes()\n",
    "X = ds.data\n",
    "Y = ds.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.5, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55015b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ESTIMATORS = 300\n",
    "\n",
    "gbclf = BaggingRegressor(warm_start=True)\n",
    "err_train_bag = []\n",
    "err_test_bag = []\n",
    "for i in range(1, MAX_ESTIMATORS+1):\n",
    "    gbclf.n_estimators = i\n",
    "    gbclf.fit(X_train, Y_train)\n",
    "    err_train_bag.append(1 - gbclf.score(X_train, Y_train))\n",
    "    err_test_bag.append(1 - gbclf.score(X_test, Y_test))\n",
    "    \n",
    "gbclf = GradientBoostingRegressor(warm_start=True, max_depth=2, learning_rate=0.1)\n",
    "err_train_gb = []\n",
    "err_test_gb = []\n",
    "for i in range(1, MAX_ESTIMATORS+1):\n",
    "    gbclf.n_estimators = i\n",
    "    gbclf.fit(X_train, Y_train)\n",
    "    err_train_gb.append(1 - gbclf.score(X_train, Y_train))\n",
    "    err_test_gb.append(1 - gbclf.score(X_test, Y_test))\n",
    "    \n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(err_train_gb, label='GB')\n",
    "plt.plot(err_train_bag, label='Bagging')\n",
    "plt.legend()\n",
    "plt.title('Train')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(err_test_gb, label='GB')\n",
    "plt.plot(err_test_bag, label='Bagging')\n",
    "plt.legend()\n",
    "plt.title('Test')\n",
    "plt.gcf().set_size_inches(15,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-ranch",
   "metadata": {
    "id": "developmental-ranch"
   },
   "source": [
    "## Многоклассовая классификация с использованием деревьев решений, случайных лесов и градиентного бустинга"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-sarah",
   "metadata": {
    "id": "vanilla-sarah"
   },
   "source": [
    "Применим каждый метод к задаче классификации и выберем оптимальную модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cubic-vehicle",
   "metadata": {
    "id": "cubic-vehicle"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "data = load_digits()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-recovery",
   "metadata": {
    "id": "impressive-recovery"
   },
   "source": [
    "Мы будем использовать набор данных digits. Это задача распознавания рукописных цифр — многозначная классификация по 10 классам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-manhattan",
   "metadata": {
    "id": "powerful-manhattan",
    "outputId": "9db564cb-8b9d-4d8f-acd1-5ee2bad5e0db"
   },
   "outputs": [],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-piano",
   "metadata": {
    "id": "prerequisite-piano",
    "outputId": "96b03983-135c-42e2-b15d-a5b4efbdee5d"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(6, 6))\n",
    "fig.suptitle(\"Training data examples\")\n",
    "\n",
    "for i in range(9):\n",
    "    img = X[i].reshape(8, 8)\n",
    "    axs[i // 3, i % 3].imshow(img)\n",
    "    axs[i // 3, i % 3].set_title(\"Class label: %s\" % y[i])\n",
    "    axs[i // 3, i % 3].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-europe",
   "metadata": {
    "id": "willing-europe"
   },
   "source": [
    "Разделите набор данных, чтобы иметь возможность проверить свою модель, используйте `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-support",
   "metadata": {
    "id": "organized-support"
   },
   "outputs": [],
   "source": [
    "# Split the dataset. Use any method you prefer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-shade",
   "metadata": {
    "id": "offshore-shade"
   },
   "source": [
    "#### Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-argument",
   "metadata": {
    "id": "automotive-argument"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create and fit decision tree with the default parameters\n",
    "# Evaluate it on the validation set. Use accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-receiver",
   "metadata": {
    "id": "demographic-receiver"
   },
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-shopper",
   "metadata": {
    "id": "collected-shopper"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create RandomForestClassifier with the default parameters\n",
    "# Fit and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-chancellor",
   "metadata": {
    "id": "facial-chancellor"
   },
   "outputs": [],
   "source": [
    "# Now let's see how the quality depends on the number of models in the ensemble\n",
    "# For each value in [5, 10, 100, 500, 1000] create a random forest with the corresponding size, fit a model and evaluate\n",
    "# How does the quality change? What number is sufficient?\n",
    "# Please write you conslusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-cartoon",
   "metadata": {
    "id": "through-cartoon"
   },
   "source": [
    "#### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-sleep",
   "metadata": {
    "id": "anticipated-sleep"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create GradientBoostingClassifier with the default parameters\n",
    "# Fit and evaluate. Compare its quality to random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-berry",
   "metadata": {
    "id": "indonesian-berry"
   },
   "outputs": [],
   "source": [
    "# Now let's see how the quality depends on the number of models in the ensemble\n",
    "# For each value in [5, 10, 100, 500, 1000] train a gradient boosting with the corresponding size\n",
    "# How does the quality change? What number is sufficient?\n",
    "# Please write you conslusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-williams",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-nurse",
   "metadata": {},
   "source": [
    "[Оригинальная статья](https://arxiv.org/pdf/1603.02754.pdf):\n",
    "\n",
    "1. Распараллеливание, оптимизация и поддержка разреженных/отсутствующих данных\n",
    "\n",
    "2. Базовый алгоритм аппроксимирует направление, вычисленное с использованием производных функции потерь второго порядка.\n",
    "\n",
    "3. Регуляризированная цель обучения: добавлены штраф за количество листьев и нормы коэффициентов.\n",
    "\n",
    "4. Предложен Weighted Quantile Sketch алгоритм для выбора точек разделения узлов дерева."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-afghanistan",
   "metadata": {},
   "source": [
    "##### Установка\n",
    "\n",
    "http://xgboost.readthedocs.io/en/latest/build.html\n",
    "\n",
    "или\n",
    "\n",
    "```pip install xgboost```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(<TRAIN DATA>, label=<TRAIN LABELS>)\n",
    "dtest = xgb.DMatrix(<TEST DATA>, label=<TEST LABELS>)\n",
    "\n",
    "param = {\n",
    "    'max_depth': 3,  # max tree depth\n",
    "    'eta': 0.3,  # learning rate / step size\n",
    "    'silent': 1,  # log verbosity\n",
    "    'objective': 'multi:softprob',  # objective function (in this case for multiclass classification task)\n",
    "    'num_class': 10}  # number of classes\n",
    "num_round = 20  # boosting iteration num\n",
    "\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "\n",
    "preds = bst.predict(dtest)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'accuracy score: {accuracy_score(y_test, best_preds):.4f}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "week0_07_gradient_boosting.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
