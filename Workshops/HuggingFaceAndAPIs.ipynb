{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека [Transformers](https://huggingface.co/transformers/) от компании Hugging Face предоставляет простой и унифицированный интерфейс для работы с современными моделями обработки естественного языка (NLP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация текста\n",
    "\n",
    "Классификация текста — это задача присвоения категории или метки данному тексту. Например, определение тональности отзыва (положительный или отрицательный). С помощью библиотеки Transformers можно легко использовать предобученные модели для этой задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "text = \"I love using the Transformers library!\"\n",
    "\n",
    "result = classifier(text)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание чат-бота\n",
    "\n",
    "Модели трансформеров могут быть использованы для создания чат-ботов, способных генерировать осмысленные ответы на введённые пользователем сообщения. Для этого часто используют модели семейства GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "chatbot = pipeline(\"text-generation\", model=\"microsoft/DialoGPT-medium\")\n",
    "\n",
    "user_input = \"Hello, how are you?\"\n",
    "\n",
    "response = chatbot(user_input, max_length=50, num_return_sequences=1)\n",
    "\n",
    "response[0]['generated_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизация текста\n",
    "\n",
    "Векторизация текста — это процесс преобразования текстовых данных в числовые векторы, которые могут быть использованы в различных задачах машинного обучения. Модели трансформеров позволяют получать эмбеддинги (векторные представления) текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "text = \"Transformers are amazing for NLP tasks.\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "sentence_embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "sentence_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос-ответная система\n",
    "\n",
    "Модели трансформеров могут быть использованы для создания систем, отвечающих на вопросы на основе заданного контекста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
    "\n",
    "context = \"Transformers library provides general-purpose architectures for NLP tasks.\"\n",
    "question = \"What does the Transformers library provide?\"\n",
    "\n",
    "answer = qa_pipeline(question=question, context=context)\n",
    "\n",
    "answer['answer']"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
