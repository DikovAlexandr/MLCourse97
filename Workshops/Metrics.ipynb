{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики для оценки моделей машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики для классификации\n",
    "В задачах классификации метрики оценивают, насколько хорошо модель предсказывает классы. \n",
    "\n",
    "Различают метрики для бинарной и многоклассовой классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "y_true = np.array([0, 1, 1, 0, 0, 1, 0, 0, 1, 0])\n",
    "y_pred = np.array([0, 1, 0, 0, 1, 1, 1, 0, 1, 0])\n",
    "y_proba = np.array([0.1, 0.9, 0.4, 0.2, 0.8, 0.95, 0.6, 0.3, 0.85, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy (Точность)\n",
    "Accuracy — это доля правильно классифицированных объектов от общего числа примеров:\n",
    "\n",
    "$$\n",
    "Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "- **Где:**  \n",
    "  - $ TP $ (True Positive) — количество верно предсказанных положительных примеров.  \n",
    "  - $ TN $ (True Negative) — количество верно предсказанных отрицательных примеров.  \n",
    "  - $ FP $ (False Positive) — количество ошибочно отнесенных к положительному классу примеров.  \n",
    "  - $ FN $ (False Negative) — количество ошибочно отнесенных к отрицательному классу примеров.  \n",
    "\n",
    "**Применение:**  \n",
    "- Хорошо подходит, когда классы сбалансированы.  \n",
    "- Не подходит при сильном дисбалансе классов, так как можно получить высокую точность, просто предсказывая преобладающий класс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision (Точность, положительная предсказательная способность)\n",
    "Precision показывает, какая доля предсказанных положительных классов действительно является положительной:\n",
    "\n",
    "$$\n",
    "Precision = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "**Применение:**  \n",
    "- Используется, когда важно минимизировать количество ложных срабатываний (FP), например, в медицинских тестах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall (Полнота, чувствительность)\n",
    "Recall показывает, какая доля реальных положительных примеров была найдена моделью:\n",
    "\n",
    "$$\n",
    "Recall = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "**Применение:**  \n",
    "- Важен в задачах, где критично не пропускать положительные примеры, например, при выявлении мошенничества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "print(\"Recall:\", recall_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-score\n",
    "F1-score — это гармоническое среднее Precision и Recall:\n",
    "\n",
    "$$\n",
    "F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}\n",
    "$$\n",
    "\n",
    "**Применение:**  \n",
    "- Используется, когда важно найти баланс между Precision и Recall, например, в задаче классификации спама."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "print(\"F1-score:\", f1_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ROC AUC (Площадь под ROC-кривой)\n",
    "ROC-кривая показывает зависимость между True Positive Rate (TPR) и False Positive Rate (FPR):\n",
    "\n",
    "$$\n",
    "TPR = \\frac{TP}{TP + FN}, \\quad FPR = \\frac{FP}{FP + TN}\n",
    "$$\n",
    "\n",
    "AUC (Area Under Curve) — это площадь под ROC-кривой. Чем больше AUC, тем лучше модель.\n",
    "\n",
    "**Применение:**  \n",
    "- Позволяет оценить модель при различных порогах классификации.  \n",
    "- Подходит для задач с несбалансированными классами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "print(\"ROC AUC:\", roc_auc_score(y_true, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Loss (Logarithmic Loss)\n",
    "Логарифмическая функция потерь измеряет расхождение между предсказанной вероятностью принадлежности к классу и реальным классом:\n",
    "\n",
    "$$\n",
    "LogLoss = -\\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right]\n",
    "$$\n",
    "\n",
    "**Применение:**  \n",
    "- Используется в задачах, где важны вероятностные предсказания, например, в кредитном скоринге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 0.45517316422941567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "print(\"Log Loss:\", log_loss(y_true, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики для регрессии\n",
    "Регрессионные метрики оценивают, насколько точно модель предсказывает числовые значения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_true = np.array([3.2, 2.8, 4.5, 3.7, 5.1])\n",
    "y_pred = np.array([3.0, 3.1, 4.2, 3.9, 5.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error (MAE)\n",
    "Средняя абсолютная ошибка (MAE) — это среднее абсолютное отклонение предсказанных значений от реальных:\n",
    "\n",
    "$$\n",
    "MAE = \\frac{1}{N} \\sum_{i=1}^{N} |y_i - \\hat{y}_i|\n",
    "$$\n",
    "\n",
    "**Преимущества:**  \n",
    "- Интерпретируемая, измеряется в тех же единицах, что и целевая переменная.  \n",
    "- Не штрафует за большие ошибки так же сильно, как MSE.\n",
    "\n",
    "**Применение:**  \n",
    "- Подходит, когда важна средняя ошибка предсказаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.21999999999999992\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE)\n",
    "Среднеквадратичная ошибка (MSE) увеличивает штраф за большие ошибки:\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "**Преимущества:**  \n",
    "- Удобна для оптимизации (градиентный спуск), так как дифференцируема.  \n",
    "- Чувствительна к выбросам.\n",
    "\n",
    "**Применение:**  \n",
    "- Используется в задачах, где важно минимизировать большие ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.05399999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error (RMSE)\n",
    "Корень из MSE:\n",
    "\n",
    "$$\n",
    "RMSE = \\sqrt{MSE}\n",
    "$$\n",
    "\n",
    "**Преимущества:**  \n",
    "- Измеряется в тех же единицах, что и целевая переменная.  \n",
    "- Подчеркивает крупные ошибки.\n",
    "\n",
    "**Применение:**  \n",
    "- Подходит, когда важно учитывать большие ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.232379000772445\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R² (Коэффициент детерминации)\n",
    "R² измеряет, какую долю дисперсии целевой переменной объясняет модель:\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n",
    "$$\n",
    "\n",
    "- $ y_i $ - истинное значение целевой переменной.\n",
    "- $ \\hat{y}_i $ - предсказанное значение модели.\n",
    "- $ \\bar{y} $ - среднее значение целевой переменной по всем наблюдениям:\n",
    "\n",
    "**Применение:**  \n",
    "- Позволяет оценить, насколько хорошо модель объясняет данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.9235560588901472\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "print(\"R² Score:\", r2_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPE (Mean Absolute Percentage Error)\n",
    "MAPE (средняя абсолютная процентная ошибка) измеряет среднюю величину ошибок модели в процентах относительно истинных значений. Это удобная метрика для оценки регрессионных моделей, поскольку позволяет интерпретировать ошибку в понятных процентных единицах.\n",
    "\n",
    "$$\n",
    "MAPE = \\frac{100\\%}{n} \\sum_{i=1}^{n} \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right|\n",
    "$$\n",
    "\n",
    "**Преимущества**\n",
    "- Легко интерпретировать, результат показывает среднюю ошибку в процентах от фактического значения.\n",
    "- Универсальна для разных масштабов, так как относительная ошибка не зависит от единиц измерения.\n",
    "\n",
    "**Ограничения:**\n",
    "- Если в данных встречаются нулевые значения \\( y_i \\), формула может приводить к делению на ноль, что требует специальных подходов (например, добавление малой константы).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 6.199428401803605\n"
     ]
    }
   ],
   "source": [
    "def mape(y_true, y_pred, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Рассчитывает среднюю абсолютную процентную ошибку (MAPE).\n",
    "    \n",
    "    Параметры:\n",
    "    y_true : массив истинных значений\n",
    "    y_pred : массив предсказанных значений\n",
    "    \n",
    "    Возвращает:\n",
    "    MAPE в процентах\n",
    "    \"\"\"\n",
    "    percentage_errors = np.abs((y_true - y_pred) / (y_true + epsilon))\n",
    "    \n",
    "    mape = np.mean(percentage_errors) * 100\n",
    "    return mape\n",
    "\n",
    "print(\"MAPE:\", mape(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики для кластеризации\n",
    "В задачах кластеризации используются метрики, оценивающие качество разбиения данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y_true = make_blobs(n_samples=100, centers=3, random_state=42)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "y_pred = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette Score (Силуэтный коэффициент)\n",
    "Измеряет, насколько объекты внутри кластера ближе друг к другу, чем к объектам из других кластеров:\n",
    "\n",
    "$$\n",
    "s_i = \\frac{b_i - a_i}{\\max(a_i, b_i)}\n",
    "$$\n",
    "\n",
    "- $ a_i $ — среднее расстояние от объекта до других объектов внутри его кластера.  \n",
    "- $ b_i $ — среднее расстояние от объекта до объектов ближайшего кластера.\n",
    "\n",
    "**Применение:**  \n",
    "- Используется для оценки качества кластеризации без истинных меток."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.8469881221532085\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "print(\"Silhouette Score:\", silhouette_score(X, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Davies-Bouldin Index\n",
    "Оценивает среднее отношение внутрикластерного расстояния к межкластерному:\n",
    "\n",
    "$$\n",
    "DBI = \\frac{1}{N} \\sum_{i=1}^{N} \\max_{j \\neq i} \\frac{\\sigma_i + \\sigma_j}{d_{ij}}\n",
    "$$\n",
    "\n",
    "**Применение:**  \n",
    "- Чем меньше значение, тем лучше кластеризация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 0.21374667882527568\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "\n",
    "print(\"Davies-Bouldin Index:\", davies_bouldin_score(X, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusted Rand Index (ARI)\n",
    "Измеряет сходство между предсказанными кластерами и истинными метками:\n",
    "\n",
    "$$\n",
    "ARI = \\frac{\\sum_{ij} \\binom{n_{ij}}{2} - \\left[\\sum_i \\binom{a_i}{2} \\sum_j \\binom{b_j}{2} \\right] / \\binom{N}{2}}{0.5 \\left[\\sum_i \\binom{a_i}{2} + \\sum_j \\binom{b_j}{2} \\right] - \\left[\\sum_i \\binom{a_i}{2} \\sum_j \\binom{b_j}{2} \\right] / \\binom{N}{2}}\n",
    "$$\n",
    "\n",
    "**Применение:**  \n",
    "- Используется, когда есть истинные метки кластеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "\n",
    "print(\"Adjusted Rand Index:\", adjusted_rand_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ConfusionMatrixDisplay',\n",
       " 'DetCurveDisplay',\n",
       " 'DistanceMetric',\n",
       " 'PrecisionRecallDisplay',\n",
       " 'PredictionErrorDisplay',\n",
       " 'RocCurveDisplay',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_base',\n",
       " '_classification',\n",
       " '_dist_metrics',\n",
       " '_pairwise_distances_reduction',\n",
       " '_pairwise_fast',\n",
       " '_plot',\n",
       " '_ranking',\n",
       " '_regression',\n",
       " '_scorer',\n",
       " 'accuracy_score',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'auc',\n",
       " 'average_precision_score',\n",
       " 'balanced_accuracy_score',\n",
       " 'brier_score_loss',\n",
       " 'calinski_harabasz_score',\n",
       " 'check_scoring',\n",
       " 'class_likelihood_ratios',\n",
       " 'classification_report',\n",
       " 'cluster',\n",
       " 'cohen_kappa_score',\n",
       " 'completeness_score',\n",
       " 'confusion_matrix',\n",
       " 'consensus_score',\n",
       " 'coverage_error',\n",
       " 'd2_absolute_error_score',\n",
       " 'd2_log_loss_score',\n",
       " 'd2_pinball_score',\n",
       " 'd2_tweedie_score',\n",
       " 'davies_bouldin_score',\n",
       " 'dcg_score',\n",
       " 'det_curve',\n",
       " 'euclidean_distances',\n",
       " 'explained_variance_score',\n",
       " 'f1_score',\n",
       " 'fbeta_score',\n",
       " 'fowlkes_mallows_score',\n",
       " 'get_scorer',\n",
       " 'get_scorer_names',\n",
       " 'hamming_loss',\n",
       " 'hinge_loss',\n",
       " 'homogeneity_completeness_v_measure',\n",
       " 'homogeneity_score',\n",
       " 'jaccard_score',\n",
       " 'label_ranking_average_precision_score',\n",
       " 'label_ranking_loss',\n",
       " 'log_loss',\n",
       " 'make_scorer',\n",
       " 'matthews_corrcoef',\n",
       " 'max_error',\n",
       " 'mean_absolute_error',\n",
       " 'mean_absolute_percentage_error',\n",
       " 'mean_gamma_deviance',\n",
       " 'mean_pinball_loss',\n",
       " 'mean_poisson_deviance',\n",
       " 'mean_squared_error',\n",
       " 'mean_squared_log_error',\n",
       " 'mean_tweedie_deviance',\n",
       " 'median_absolute_error',\n",
       " 'multilabel_confusion_matrix',\n",
       " 'mutual_info_score',\n",
       " 'nan_euclidean_distances',\n",
       " 'ndcg_score',\n",
       " 'normalized_mutual_info_score',\n",
       " 'pair_confusion_matrix',\n",
       " 'pairwise',\n",
       " 'pairwise_distances',\n",
       " 'pairwise_distances_argmin',\n",
       " 'pairwise_distances_argmin_min',\n",
       " 'pairwise_distances_chunked',\n",
       " 'pairwise_kernels',\n",
       " 'precision_recall_curve',\n",
       " 'precision_recall_fscore_support',\n",
       " 'precision_score',\n",
       " 'r2_score',\n",
       " 'rand_score',\n",
       " 'recall_score',\n",
       " 'roc_auc_score',\n",
       " 'roc_curve',\n",
       " 'root_mean_squared_error',\n",
       " 'root_mean_squared_log_error',\n",
       " 'silhouette_samples',\n",
       " 'silhouette_score',\n",
       " 'top_k_accuracy_score',\n",
       " 'v_measure_score',\n",
       " 'zero_one_loss']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "# help(sklearn.metrics)\n",
    "dir(sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
