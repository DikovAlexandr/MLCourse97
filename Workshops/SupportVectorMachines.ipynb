{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8SDp-UFxf3_"
      },
      "source": [
        "# Support Vector Machines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPp9UejBxf4E"
      },
      "source": [
        "Метод опорных векторов (SVM) — это особенно мощный и гибкий класс контролируемых алгоритмов как для классификации, так и для регрессии."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lIZ9IUjYxf4F",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEd6iF5Qxf4H"
      },
      "source": [
        "## Идея"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agf9i0D5xf4H",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "4852be65-54b3-4343-f062-8e5c766547c1"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "X, y = make_blobs(n_samples=50, centers=2,\n",
        "                  random_state=0, cluster_std=0.60)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJM4Dfjqxf4I"
      },
      "source": [
        "Линейный классификатор попытается провести прямую линию, разделяющую два набора данных, и тем самым создать модель для классификации.\n",
        "Для двумерных данных, подобных показанным здесь, это задача, которую мы могли бы выполнить вручную.\n",
        "Но мы сразу же видим проблему: существует более одной возможной разделительной линии, которая может идеально различать два класса."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkD8gbLIxf4J",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "475430cc-8cf3-47ea-f894-e36358f8e7e0"
      },
      "outputs": [],
      "source": [
        "xfit = np.linspace(-1, 3.5)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "plt.plot([0.6], [2.1], 'x', color='red', markeredgewidth=2, markersize=10)\n",
        "\n",
        "for m, b in [(1, 0.65), (0.5, 1.6), (-0.2, 2.9)]:\n",
        "    plt.plot(xfit, m * xfit + b, '-k')\n",
        "\n",
        "plt.xlim(-1, 3.5);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtDuHW4pxf4J"
      },
      "source": [
        "Это три разных разделителя, которые, тем не менее, хорошо различают эти примеры.\n",
        "В зависимости от того, какой из них вы выберете, новой точке данных (например, отмеченной «X» на этом графике) будет присвоена разная метка.\n",
        "Очевидно, что наша простая интуиция «проведения линии между классами» недостаточно хороша."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP4QkjiMxf4K"
      },
      "source": [
        "## Метод опорных векторов: максимизация отступа\n",
        "\n",
        "Метод опорных векторов предлагают один из способов улучшить это.\n",
        "Интуиция такова: вместо того, чтобы просто рисовать линию нулевой ширины между классами, мы можем нарисовать вокруг каждой линии *отступ* некоторой ширины, до ближайшей точки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPsPFS_Mxf4K",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "a96af887-9eeb-4764-bf06-0689af308c26"
      },
      "outputs": [],
      "source": [
        "xfit = np.linspace(-1, 3.5)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "\n",
        "for m, b, d in [(1, 0.65, 0.33), (0.5, 1.6, 0.55), (-0.2, 2.9, 0.2)]:\n",
        "    yfit = m * xfit + b\n",
        "    plt.plot(xfit, yfit, '-k')\n",
        "    plt.fill_between(xfit, yfit - d, yfit + d, edgecolor='none',\n",
        "                     color='lightgray', alpha=0.5)\n",
        "\n",
        "plt.xlim(-1, 3.5);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEC1Lx53xf4K"
      },
      "source": [
        "Линию, которая максимизирует этот отступ, мы и выберем в качестве оптимальной модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9CCAB0zxf4L"
      },
      "source": [
        "### Обучени метода опорных векторов\n",
        "\n",
        "Будем использовать классификатор опорных векторов Scikit-Learn (`SVC`) в качестве модели SVM на этих данных.\n",
        "На данный момент мы будем использовать линейное ядро ​​и установим параметр `C` на очень большое число."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jm2jK0wTxf4L",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "bf41c1a7-7f97-4c15-8119-b2376e45bfcc"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC # \"Support vector classifier\"\n",
        "model = SVC(kernel='linear', C=1E10)\n",
        "model.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi_APtndxf4L"
      },
      "source": [
        "Функция, которая построит для нас границы отступа SVM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ia-gPM7pxf4L",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "def plot_svc_decision_function(model, ax=None, plot_support=True):\n",
        "    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n",
        "    if ax is None:\n",
        "        ax = plt.gca()\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "\n",
        "    # create grid to evaluate model\n",
        "    x = np.linspace(xlim[0], xlim[1], 30)\n",
        "    y = np.linspace(ylim[0], ylim[1], 30)\n",
        "    Y, X = np.meshgrid(y, x)\n",
        "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
        "    P = model.decision_function(xy).reshape(X.shape)\n",
        "\n",
        "    # plot decision boundary and margins\n",
        "    ax.contour(X, Y, P, colors='k',\n",
        "               levels=[-1, 0, 1], alpha=0.5,\n",
        "               linestyles=['--', '-', '--'])\n",
        "\n",
        "    # plot support vectors\n",
        "    if plot_support:\n",
        "        ax.scatter(model.support_vectors_[:, 0],\n",
        "                   model.support_vectors_[:, 1],\n",
        "                   s=300, linewidth=1, edgecolors='black',\n",
        "                   facecolors='none');\n",
        "    ax.set_xlim(xlim)\n",
        "    ax.set_ylim(ylim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxvmIGnDxf4M",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "9fa12344-0f1e-4159-fdc3-b047acbb9183"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "plot_svc_decision_function(model);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp1jl1nKxf4M"
      },
      "source": [
        "Это разделительная линия, которая максимизирует разницу между двумя наборами точек.\n",
        "Обратите внимание, что несколько точек обучения просто касаются границы.\n",
        "\n",
        "Эти точки являются основными элементами для обучения. Это *опорные векторы* дающие алгоритму его название.\n",
        "В Scikit-Learn идентификаторы этих точек хранятся в атрибуте `support_vectors_` классификатора."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiynbIWpxf4M",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "59463626-18f8-4d9a-9704-cdb17b142151"
      },
      "outputs": [],
      "source": [
        "model.support_vectors_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09SwH2ubxf4M"
      },
      "source": [
        "Ключом к успеху этого классификатора является то, что для обучения важны только положения опорных векторов, а любые точки, находящиеся дальше от границы, но на правильной стороне, не влияют на обучение.\n",
        "\n",
        "Технически это происходит потому, что эти точки не вносят вклад в функцию потерь, используемую для подгонки модели, поэтому их положение и количество не имеют значения, пока они не пересекают границу.\n",
        "\n",
        "Мы можем увидеть это, например, если построим график модели, обученной на основе первых 60 точек и первых 120 точек этого набора данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3xmJKbmxf4M",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "1648cebb-8eac-48f2-c7d0-e70eaf60347c"
      },
      "outputs": [],
      "source": [
        "def plot_svm(N=10, ax=None):\n",
        "    X, y = make_blobs(n_samples=200, centers=2,\n",
        "                      random_state=0, cluster_std=0.60)\n",
        "    X = X[:N]\n",
        "    y = y[:N]\n",
        "    model = SVC(kernel='linear', C=1E10)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    ax = ax or plt.gca()\n",
        "    ax.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "    ax.set_xlim(-1, 4)\n",
        "    ax.set_ylim(-1, 6)\n",
        "    plot_svc_decision_function(model, ax)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
        "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
        "for axi, N in zip(ax, [60, 120]):\n",
        "    plot_svm(N, axi)\n",
        "    axi.set_title('N = {0}'.format(N))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WfP77NRxf4N"
      },
      "source": [
        "Эта нечувствительность к точному поведению удаленных точек является одной из сильных сторон модели SVM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dySL4fhgxf4N"
      },
      "source": [
        "Виджеты IPython для интерактивного просмотра этой функции модели SVM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ba29c3a8344b463a8848a4a7bfec4da8"
          ]
        },
        "id": "cbczl7clxf4N",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "0f88aa57-c820-4716-e25d-a64693fcf34d"
      },
      "outputs": [],
      "source": [
        "from ipywidgets import interact, fixed\n",
        "interact(plot_svm, N=(10, 200), ax=fixed(None));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV2oiYfsxf4N"
      },
      "source": [
        "### Ядра SVM \n",
        "\n",
        "Возможности SVM могут быть расширены, за счет использования *ядер*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGMBAT-4xf4N",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "4d4e08e2-49d4-47b2-bbda-102e2ccdd11d"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_circles\n",
        "X, y = make_circles(100, factor=.1, noise=.1)\n",
        "\n",
        "clf = SVC(kernel='linear').fit(X, y)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "plot_svc_decision_function(clf, plot_support=False);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYzs9A02xf4O"
      },
      "source": [
        "Очевидно, что никакая линейная дискриминация *никогда* не сможет разделить эти данные.\n",
        "\n",
        "Здесь может бють использована *радиальная базисная функция* (RBF) с центром в средней группе."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UwcgGzCvxf4O",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "r = np.exp(-(X ** 2).sum(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWfe58E4xf4O"
      },
      "source": [
        "Мы можем визуализировать это дополнительное измерение данных с помощью трехмерного графика."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3ATVzfMxf4O",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "4217b52f-6539-41b8-9081-cd22caa4a582"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits import mplot3d\n",
        "\n",
        "ax = plt.subplot(projection='3d')\n",
        "ax.scatter3D(X[:, 0], X[:, 1], r, c=y, s=50, cmap='autumn')\n",
        "ax.view_init(elev=20, azim=30)\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_zlabel('r');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "986nwAu2xf4O"
      },
      "source": [
        "Мы видим, что с этим дополнительным измерением данные становятся тривиально линейно разделимыми, если нарисовать разделяющую плоскость, скажем, при *r*=0,7.\n",
        "\n",
        "В этом случае нам пришлось выбрать и тщательно настроить нашу проекцию: если бы мы не центрировали нашу радиальную базисную функцию в правильном месте, мы бы не увидели таких чистых, линейно разделимых результатов.\n",
        "В общем, необходимость делать такой выбор является проблемой: мы хотели бы каким-то образом автоматически находить лучшие базисные функции для использования.\n",
        "\n",
        "Одна из стратегий для этого — вычислить базисную функцию, центрированную в *каждой* точке в наборе данных, и позволить алгоритму SVM работать с этими результатами.\n",
        "\n",
        "Этот тип преобразования базисной функции известен как *ядерное преобразование*, поскольку он основан на отношении подобия (или ядре) между каждой парой точек.\n",
        "\n",
        "Потенциальная проблема с этой стратегией — проецированием $N$ точек в $N$ измерений — заключается в том, что она может стать очень вычислительно дорогой по мере увеличения $N$.\n",
        "Однако благодаря небольшой аккуратной процедуре, известной как [*ядерный трюк*](https://en.wikipedia.org/wiki/Kernel_trick), подгонка данных, преобразованных ядром, может быть выполнена неявно, то есть без построения полного $N$-мерного представления проекции ядра.\n",
        "\n",
        "Этот трюк встроен в SVM и является одной из причин, по которой этот метод настолько эффективен.\n",
        "\n",
        "В Scikit-Learn мы можем применить SVM с ядром, просто изменив наше линейное ядро ​​на ядро ​​RBF, используя гиперпараметр модели `kernel`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPNtoP5ixf4P",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "9d3a8a84-f834-4c7e-be8e-12eb7fcb25ec"
      },
      "outputs": [],
      "source": [
        "clf = SVC(kernel='rbf', C=1E6)\n",
        "clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5uI6qv1xf4P"
      },
      "source": [
        "Давайте используем нашу ранее определенную функцию для визуализации подгонки и определения опорных векторов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEAZcvjRxf4P",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "d6c5650e-8745-4ceb-9c7a-4350b1c86328"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "plot_svc_decision_function(clf)\n",
        "plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1],\n",
        "            s=300, lw=1, facecolors='none');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuyhjPRKxf4P"
      },
      "source": [
        "Эта стратегия преобразования ядра часто используется в машинном обучении для превращения быстрых линейных методов в быстрые нелинейные методы, особенно для моделей, в которых можно использовать трюк с ядром."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81oeVrs_xf4P"
      },
      "source": [
        "### Настройка SVM: смягчение отступа\n",
        "\n",
        "До сих пор наше обсуждение было сосредоточено вокруг очень чистых наборов данных, в которых существует идеальная граница разделения.\n",
        "\n",
        "Но что, если ваши данные имеют некоторую степень перекрытия?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1Jqb9waxf4Q",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "8818e0e6-7562-4267-deb3-597bada5c179"
      },
      "outputs": [],
      "source": [
        "X, y = make_blobs(n_samples=100, centers=2,\n",
        "                  random_state=0, cluster_std=1.2)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VAF-aUwxf4Q"
      },
      "source": [
        "Чтобы справиться с этим случаем, реализация SVM имеет немного фактора подгонки, который «смягчает» границу: то есть, она позволяет некоторым точкам проникать в границу, если это позволяет лучше подогнать ее.\n",
        "Жесткость границы контролируется параметром настройки `C`.\n",
        "Для очень большого `C` граница жесткая, и точки не могут лежать в ней.\n",
        "Для меньшего `C` граница мягче и может расширяться, охватывая некоторые точки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuQWMhY9xf4Q",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "a9b5e11d-b520-42d3-9837-d367ad0bdefb"
      },
      "outputs": [],
      "source": [
        "X, y = make_blobs(n_samples=100, centers=2,\n",
        "                  random_state=0, cluster_std=0.8)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
        "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
        "\n",
        "for axi, C in zip(ax, [10.0, 0.1]):\n",
        "    model = SVC(kernel='linear', C=C).fit(X, y)\n",
        "    axi.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
        "    plot_svc_decision_function(model, axi)\n",
        "    axi.scatter(model.support_vectors_[:, 0],\n",
        "                model.support_vectors_[:, 1],\n",
        "                s=300, lw=1, facecolors='none');\n",
        "    axi.set_title('C = {0:.1f}'.format(C), size=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I22MFXlIxf4U"
      },
      "source": [
        "## Пример: Распознавание лиц\n",
        "\n",
        "В качестве примера для метода опорных векторов рассмотрим задачу распознавания лиц.\n",
        "\n",
        "Мы будем использовать набор данных Labeled Faces in the Wild, который состоит из нескольких тысяч сопоставленных фотографий различных публичных личностей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZuFX6Yoxf4U",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "f42b64d6-5dbf-49c6-c5bc-864da07f1e7a"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_lfw_people\n",
        "faces = fetch_lfw_people(min_faces_per_person=60)\n",
        "print(faces.target_names)\n",
        "print(faces.images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu4oQ-wUxf4V",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "301bc00d-b327-4494-f9c7-d46459d2ab30"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(3, 5, figsize=(8, 6))\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    axi.imshow(faces.images[i], cmap='bone')\n",
        "    axi.set(xticks=[], yticks=[],\n",
        "            xlabel=faces.target_names[faces.target[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1YC7O39xf4V"
      },
      "source": [
        "Мы могли бы продолжить, просто используя каждое значение пикселя как признак, но часто бывает эффективнее использовать какой-либо препроцессор для извлечения более значимых признаков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8DElO_JDxf4V",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pca = PCA(n_components=150, whiten=True,\n",
        "          svd_solver='randomized', random_state=42)\n",
        "svc = SVC(kernel='rbf', class_weight='balanced')\n",
        "model = make_pipeline(pca, svc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "16A9tYDyxf4W",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(faces.data, faces.target,\n",
        "                                                random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CbNEkTIxf4W"
      },
      "source": [
        "Мы можем использовать перекрестную проверку (кросс валидацию) поиска по сетке для изучения комбинаций параметров.\n",
        "\n",
        "Здесь мы настроим `C` (который управляет жесткостью границ) и `gamma` (который управляет размером ядра радиальной базисной функции) и определим лучшую модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsXg2uaNxf4W",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "178d719f-1bfb-42d2-f4e0-e0784c33b07a"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {'svc__C': [1, 5, 10, 50],\n",
        "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
        "grid = GridSearchCV(model, param_grid)\n",
        "\n",
        "%time grid.fit(Xtrain, ytrain)\n",
        "print(grid.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nSqBPPCxf4W"
      },
      "source": [
        "Оптимальные значения попадают в середину нашей сетки; если бы они попадали на края, нам бы хотелось расширить сетку, чтобы убедиться, что мы нашли истинный оптимум."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2Dmmcbdvxf4W",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = grid.best_estimator_\n",
        "yfit = model.predict(Xtest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq4IWpFKxf4X"
      },
      "source": [
        "Давайте рассмотрим несколько тестовых изображений вместе с их прогнозируемыми значениями."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWbD4kv6xf4X",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "8f6e05a0-2cd9-4f83-a234-78126dfea87b"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(4, 6)\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    axi.imshow(Xtest[i].reshape(62, 47), cmap='bone')\n",
        "    axi.set(xticks=[], yticks=[])\n",
        "    axi.set_ylabel(faces.target_names[yfit[i]].split()[-1],\n",
        "                   color='black' if yfit[i] == ytest[i] else 'red')\n",
        "fig.suptitle('Predicted Names; Incorrect Labels in Red', size=14);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcukxAYwxf4X",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "c91b6ca9-b0c4-49b9-b8eb-a621f80e9027"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(ytest, yfit,\n",
        "                            target_names=faces.target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6o-Jmo5xf4Y",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "532fecff-49d5-41a3-9557-c8d98dff8bb9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "mat = confusion_matrix(ytest, yfit)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d',\n",
        "            cbar=False, cmap='Blues',\n",
        "            xticklabels=faces.target_names,\n",
        "            yticklabels=faces.target_names)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9xQMcvpxf4Y"
      },
      "source": [
        "Для реальной задачи распознавания лиц, в которой фотографии не обрезаются заранее, единственное отличие в схеме классификации лиц заключается в выборе признаков: нужно будет использовать более сложный алгоритм для поиска лиц и извлечения признаков.\n",
        "Для такого рода приложений одним из вариантов является использование [OpenCV](http://opencv.org), который включает предварительно обученные реализации современных инструментов извлечения признаков для изображений в целом и лиц в частности."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "jupytext": {
      "formats": "ipynb,md"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
