{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция 5: Введение в нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Архитектура"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Нейрон** — базовая вычислительная единица нейронной сети. Каждый нейрон получает на вход вектор значений, умножает его на вектор весов, прибавляет смещение и пропускает результат через функцию активации. Математически это описывается формулой:\n",
    "$$\n",
    "a = \\sigma\\left(\\sum_{i=1}^{n} w_i x_i + b\\right),\n",
    "$$\n",
    "где:\n",
    "- $x_i$ — входные данные,\n",
    "- $w_i$ — соответствующие веса,\n",
    "- $b$ — смещение (bias),\n",
    "- $\\sigma$ — функция активации (например, Sigmoid, ReLU, tanh).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Структура нейронной сети** включает следующие компоненты:\n",
    "- **Входной слой:** Принимает исходные данные и передаёт их на последующие слои.\n",
    "- **Скрытые слои:** Один или более слоев, где происходит обработка информации. Количество и размер скрытых слоев определяют глубину сети. Слои бывают разных типов в зависимости от задачи.\n",
    "- **Выходной слой:** Выдает окончательный результат модели (например, регрессионное значение или вероятности классов)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.researchgate.net/profile/Sufyan-Al-Janabi/publication/335856901/figure/fig2/AS:804017303191552@1568704071230/a-Simple-neural-network-architecture-b-Simple-architecture-of-deep-neural-network.ppm\" alt=\"Описание изображения\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Входной слой (Input Layer)\n",
    "- Принимает входные данные и передает их в сеть для дальнейшей обработки.\n",
    "- Его основная задача преобразовать данные в форму, пригодную для обработки. Преобразует данные в признаковое пространство. Требует векторизованного (их называют эмбеддинги) или матричного представления данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "num_features = 10\n",
    "input_tensor = torch.randn(batch_size, num_features)\n",
    "\n",
    "print(\"Входной тензор:\")\n",
    "print(input_tensor)\n",
    "print(\"Размер входного тензора:\", input_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полносвязный слой (Dense, Fully Connected Layer)\n",
    "- Является базовым строительным блоком нейронной сети.\n",
    "- Выполняет линейное преобразование входного вектора с последующей нелинейной активацией.\n",
    "- Формула работы нейрона:\n",
    "  $$\n",
    "  a = \\sigma(Wx + b),\n",
    "  $$\n",
    "  где:\n",
    "  - $W$ — матрица весов,\n",
    "  - $b$ — смещение (bias),\n",
    "  - $\\sigma$ — функция активации (ReLU, Sigmoid, tanh и т.д.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "in_features = 10 # - размерность входного вектора\n",
    "out_features = 20 # - размерность выходного вектора\n",
    "bias = True # - использование смещения (по умолчанию True)\n",
    "\n",
    "fc_layer = nn.Linear(in_features, out_features, bias)\n",
    "\n",
    "batch_size = 32\n",
    "x = torch.randn(batch_size, in_features)\n",
    "output = fc_layer(x)\n",
    "\n",
    "print(\"Размер входного тензора:\", x.shape)\n",
    "print(\"Размер выхода полносвязного слоя:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сверточный слой (Convolutional Layer)\n",
    "- Применяется для обработки данных с пространственной структурой.\n",
    "- Работает с локальными областями входных данных, используя фильтры (ядра свертки), которые перемещаются по изображению.\n",
    "- Применяется в обработке изображений и видео, сигналов и временных рядов.\n",
    "\n",
    "Параметры:\n",
    "- *Размер ядра (Kernel Size):* Размер фильтра.\n",
    "- *Шаг (Stride):* Количество пикселей, на которое перемещается фильтр.\n",
    "- *Отступ (Padding):* Добавление дополнительных значений по краям для сохранения размерности.\n",
    "- *Количество каналов (Depth):* Количество применяемых фильтров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/19/2D_Convolution_Animation.gif\" alt=\"Описание изображения\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "image, label = dataset[0]\n",
    "\n",
    "in_channels = 1 # - число входных каналов\n",
    "out_channels = 8 # - число фильтров (выходных каналов)\n",
    "kernel_size = 3 # - размер ядра свертки\n",
    "stride = 1 # - шаг свертки (по умолчанию 1)\n",
    "padding = 1 # - заполнение краев (для сохранения размерности)\n",
    "\n",
    "conv_layer = nn.Conv2d(in_channels, out_channels, \n",
    "                       kernel_size, stride, padding)\n",
    "\n",
    "input_tensor = image.unsqueeze(0)\n",
    "conv_output = F.relu(conv_layer(input_tensor))\n",
    "\n",
    "print(\"Размер входного тензора:\", input_tensor.shape)\n",
    "print(\"Размер выхода сверточного слоя:\", conv_output.shape)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Входное изображение\")\n",
    "plt.imshow(image.permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Выход первого свертки\")\n",
    "output_feature = conv_output[0, 0].detach().numpy()\n",
    "plt.imshow(output_feature, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слои пулинга (Pooling Layers)\n",
    "- Сокращают пространственные размеры данных, помогая уменьшить вычислительную сложность и предотвращая переобучение.\n",
    "- Неразрывно связан со сверточными слоями, позволяя архитектуре в целом видеть паттерны на изображении, выделяет наиболее существенные признаки.\n",
    "\n",
    "Варианты:\n",
    "- *Max Pooling:* Выбирает максимум из выборки.\n",
    "- *Average Pooling:* Вычисляет среднее значение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://nico-curti.github.io/NumPyNet/NumPyNet/images/maxpool.gif\" alt=\"Описание изображения\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "image, label = dataset[0]\n",
    "\n",
    "kernel_size = 3 # - размер окна пулинга\n",
    "stride = 3 # - шаг пулинга (по умолчанию равен kernel_size)\n",
    "padding = 0 # - заполнение (обычно 0)\n",
    "pool_layer = nn.MaxPool2d(kernel_size, stride, padding)\n",
    "\n",
    "input_tensor = image.unsqueeze(0)\n",
    "pooled_output = pool_layer(input_tensor)\n",
    "\n",
    "print(\"Входное изображение shape:\", input_tensor.shape)\n",
    "print(\"После пулинга shape:\", pooled_output.shape)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Входное изображение\")\n",
    "plt.imshow(image.permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Изображение после пулинга\")\n",
    "pooled_img = pooled_output[0, 0].detach().numpy()\n",
    "plt.imshow(pooled_img, cmap='viridis')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Рекуррентный слой (Recurrent Layer)\n",
    "- Применяется для работы с последовательными данными, учитывая порядок элементов.\n",
    "\n",
    "Варианты:\n",
    "- *RNN (Recurrent Neural Network):* Простая структура, но подверженная проблемам исчезающего и \"взрывающегося\" градиента.\n",
    "- *LSTM (Long Short-Term Memory):* Имеет механизмы запоминания и забывания, позволяет работать с длительными зависимостями.\n",
    "- *GRU (Gated Recurrent Units):* Более простой вариант, чем LSTM, но с подобной функциональностью.\n",
    "- *State space models (Mamba)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20231204130132/RNN-vs-FNN-660.png\" alt=\"Описание изображения\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "class LSTMSequenceModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=1):\n",
    "        super(LSTMSequenceModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, # - размерность входного вектора\n",
    "                            hidden_dim, # - размерность скрытого состояния\n",
    "                            num_layers, # - число слоев LSTM\n",
    "                            batch_first=True # - если True, первый размер соответствует batch_size\n",
    "                            )\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embed = self.embedding(x)\n",
    "        out, (h_n, _) = self.lstm(embed)\n",
    "        last_hidden = h_n[-1]\n",
    "        logits = self.fc(last_hidden)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def create_dataset(sequence, seq_len):\n",
    "    \"\"\"\n",
    "    Создает датасет для предсказания следующего токена.\n",
    "    Для последовательности [t0, t1, t2, ...] формируются примеры:\n",
    "    вход: [t0, t1, ..., t(seq_len-1)], \n",
    "    цель: t(seq_len)\n",
    "    \"\"\"\n",
    "    inputs, targets = [], []\n",
    "    for i in range(len(sequence) - seq_len):\n",
    "        inputs.append(sequence[i:i + seq_len])\n",
    "        targets.append(sequence[i + seq_len])\n",
    "    return torch.tensor(inputs, dtype=torch.long), torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "\n",
    "vocab = [0, 1, 2]\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 8\n",
    "hidden_dim = 16\n",
    "seq_len = 5\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "base_pattern = [0, 1, 2]\n",
    "sequence = base_pattern * 50\n",
    "\n",
    "inputs, targets = create_dataset(sequence, seq_len)\n",
    "\n",
    "model = LSTMSequenceModel(vocab_size, embed_dim, hidden_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(inputs)\n",
    "    loss = criterion(logits, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(losses, label='Потери')\n",
    "plt.xlabel('Эпоха')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Обучение LSTM для предсказания следующего элемента')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "model.eval()\n",
    "test_seq = sequence[-seq_len:]\n",
    "test_input = torch.tensor([test_seq], dtype=torch.long)\n",
    "with torch.no_grad():\n",
    "    logits = model(test_input)\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "    predicted_token = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "print(\"Тестовая последовательность:\", test_seq)\n",
    "print(\"Предсказанный следующий элемент:\", predicted_token)\n",
    "print(\"Вероятности:\", np.round(probabilities[0].numpy(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слои внимания (Attention Layers)\n",
    "- Позволяют модели фокусироваться на наиболее значимых частях входных данных.\n",
    "  \n",
    "Варианты:\n",
    "- *Cross-Attention:* \n",
    "- *Self-Attention:* Используется для обработки последовательностей, где каждый элемент взаимодействует с другими.\n",
    "- *Multi-Head Attention:* Позволяет модели учитывать информацию с разных \"углов зрения\", что особенно важно в трансформерах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://jalammar.github.io/images/t/self-attention-output.png\" alt=\"Описание изображения\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://jalammar.github.io/images/t/transformer_decoding_2.gif\" alt=\"Описание изображения\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class AttentionSequenceModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, max_seq_len, hidden_dim):\n",
    "        super(AttentionSequenceModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_seq_len, embed_dim)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "        self.fc = nn.Linear(embed_dim, vocab_size)\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.size()\n",
    "        token_emb = self.embedding(x)\n",
    "        positions = torch.arange(seq_len, device=x.device).unsqueeze(0).expand(batch_size, seq_len)\n",
    "        pos_emb = self.pos_embedding(positions)\n",
    "        x_emb = token_emb + pos_emb\n",
    "\n",
    "        attn_mask = torch.triu(torch.ones(seq_len, seq_len, device=x.device)\n",
    "                               * float('-inf'), diagonal=1)\n",
    "        attn_output, _ = self.attention(x_emb, x_emb, x_emb, attn_mask=attn_mask)\n",
    "        last_output = attn_output[:, -1, :]\n",
    "        logits = self.fc(last_output)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def create_dataset(sequence, seq_len):\n",
    "    \"\"\"\n",
    "    Создаем датасет для предсказания следующего токена (аналогично LSTM-примера).\n",
    "    \"\"\"\n",
    "    inputs, targets = [], []\n",
    "    for i in range(len(sequence) - seq_len):\n",
    "        inputs.append(sequence[i:i + seq_len])\n",
    "        targets.append(sequence[i + seq_len])\n",
    "    return torch.tensor(inputs, dtype=torch.long), torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "\n",
    "vocab = [0, 1, 2]\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 8\n",
    "num_heads = 2\n",
    "max_seq_len = 10\n",
    "hidden_dim = 16\n",
    "seq_len = 5\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "base_pattern = [0, 1, 2]\n",
    "sequence = base_pattern * 50\n",
    "\n",
    "inputs, targets = create_dataset(sequence, seq_len)\n",
    "\n",
    "model = AttentionSequenceModel(vocab_size, embed_dim, num_heads, max_seq_len, hidden_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(inputs)\n",
    "    loss = criterion(logits, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(losses, label='Потери')\n",
    "plt.xlabel(\"Эпоха\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Обучение модели внимания для предсказания следующего элемента\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "model.eval()\n",
    "test_seq = sequence[-seq_len:]\n",
    "test_input = torch.tensor([test_seq], dtype=torch.long)\n",
    "with torch.no_grad():\n",
    "    logits = model(test_input)  # -> [1, vocab_size]\n",
    "    probabilities = torch.softmax(logits, dim=1)\n",
    "    predicted_token = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "print(\"Тестовая последовательность:\", test_seq)\n",
    "print(\"Предсказанный следующий элемент:\", predicted_token)\n",
    "print(\"Вероятности:\", np.round(probabilities[0].numpy(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слой нормализации (Normalization Layer)\n",
    "- Повышает стабильность и скорость обучения, нормализуя активации внутри слоев.\n",
    "- Снижает проблемы исчезающего или \"взрывающегося\" градиента.\n",
    "  \n",
    "Варианты:\n",
    "- *Batch Normalization:* Нормализация по батчам.\n",
    "- *Layer Normalization:* Нормализация по признакам отдельного образца.\n",
    "- *Instance Normalization и Group Normalization:* Используются в специфичных архитектурах (например, в задачах стилизации изображений)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://theaisummer.com/static/ac89fbcf1c115f07ae68af695c28c4a0/ee604/normalization.png\" alt=\"Описание изображения\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "image, label = dataset[0]\n",
    "\n",
    "num_features = 1 # - число входных каналов\n",
    "bn_layer = nn.BatchNorm2d(num_features)\n",
    "\n",
    "input_tensor = image.unsqueeze(0)\n",
    "mean_before = input_tensor.mean(dim=[0, 2, 3])\n",
    "std_before = input_tensor.std(dim=[0, 2, 3])\n",
    "\n",
    "normalized_image = bn_layer(input_tensor)\n",
    "\n",
    "mean_after = normalized_image.mean(dim=[0, 2, 3])\n",
    "std_after = normalized_image.std(dim=[0, 2, 3])\n",
    "\n",
    "print(\"Статистика до нормализации:\")\n",
    "print(f\"Mean: {float(mean_before):.3f}\")\n",
    "print(f\"Std: {float(std_before):.3f}\")\n",
    "print(\"Статистика после нормализации:\")\n",
    "print(f\"Mean: {float(mean_after):.3f}\")\n",
    "print(f\"Std: {float(std_after):.3f}\")\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Входное изображение\")\n",
    "plt.imshow(image.permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Изображение после нормализации\")\n",
    "normalized_img = normalized_image[0, 0].detach().numpy()\n",
    "plt.imshow(normalized_img, cmap='viridis')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слой регуляризации\n",
    "- Применяется для уменьшения переобучения модели за счет внесения случайности или ограничения значений параметров.\n",
    "\n",
    "Варианты:\n",
    "- *Dropout:* Случайное обнуление части нейронов, выбранных случайно во время обучения, что позволяет модели не слишком фокусироваться на связях между конкретными нейронами.\n",
    "- [не слой, но все же] *L1 / L2 регуляризация:* Штрафование величины весов в функции потерь. Аналогично тому, как это было в линейных моделях.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://editor.analyticsvidhya.com/uploads/112801.gif\" alt=\"Описание изображения\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "p = 0.5 # - вероятность зануления элемента входного тензора\n",
    "dropout_layer = nn.Dropout(p)\n",
    "\n",
    "input_tensor = torch.ones(100)\n",
    "\n",
    "dropout_layer.train()\n",
    "output = dropout_layer(input_tensor)\n",
    "\n",
    "num_zeros = (output == 0).sum().item()\n",
    "total_elements = output.numel()\n",
    "fraction_dropped = num_zeros / total_elements\n",
    "\n",
    "print(f\"Доля зануленных элементов: {fraction_dropped:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слои соединений Residual Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Позволяют прямую передачу информации от одного слоя к другому, пропуская несколько промежуточных слоев.\n",
    "- Способствуют лучшей передаче градиентов в глубоких сетях, решая проблему исчезающего градиента.\n",
    "\n",
    "Применение:\n",
    "- *ResNet:* Глубокие сверточные сети для задач классификации изображений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/ba/ResBlock.png/1200px-ResBlock.png\" alt=\"Описание изображения\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "class_index_url = (\n",
    "    \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
    ")\n",
    "response = requests.get(class_index_url)\n",
    "json_str = response.content.decode(\"utf-8-sig\")\n",
    "class_idx = json.loads(json_str)\n",
    "idx2label = {int(key): value[1] for key, value in class_idx.items()}\n",
    "\n",
    "image_url = (\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/2/26/YellowLabradorLooking_new.jpg\"\n",
    ")\n",
    "response = requests.get(image_url)\n",
    "image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "input_tensor = preprocess(image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "probabilities = F.softmax(output[0], dim=0)\n",
    "\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 3)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"Результаты предсказания:\")\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(f\"{idx2label[top5_catid[i].item()]}: {top5_prob[i].item() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выходной слой (Output Layer)\n",
    "- Формирует окончательное предсказание, преобразуя признаки, полученные из предыдущих слоев.\n",
    "\n",
    "Варианты:\n",
    "- Для *задач классификации:* \n",
    "  - Слой с функцией Softmax для многоклассовой классификации.\n",
    "  - Слой с функцией Sigmoid для двоичной классификации.\n",
    "- Для *задач регрессии:*\n",
    "  - Линейный слой, зачастую без дополнительной функции активации или с подходящей активацией в зависимости от специфики задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://images.contentstack.io/v3/assets/bltac01ee6daa3a1e14/blte5e1674e3883fab3/65ef8ba4039fdd4df8335b7c/img_blog_image1_inline_(2).png?width=1024&disable=upscale&auto=webp\" alt=\"Описание изображения\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "batch_size = 5\n",
    "in_features = 10 # - размер входного вектора\n",
    "out_features = 2 # - число классов\n",
    "linear_layer = nn.Linear(in_features, out_features)\n",
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "x = torch.randn(batch_size, in_features)\n",
    "logits = linear_layer(x)\n",
    "probabilities = softmax(logits)\n",
    "\n",
    "print(\"Logits:\\n\", logits.detach().numpy())\n",
    "print(\"Probabilities:\\n\", probabilities.detach().numpy())\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(np.arange(out_features), probabilities[0].detach().numpy(), alpha=0.7)\n",
    "plt.xlabel(\"Класс\")\n",
    "plt.ylabel(\"Вероятность\")\n",
    "plt.title(\"Распределение вероятностей для первого примера (Softmax Output)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гиперпараметры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Гиперпараметры** — это параметры, которые задаются до начала обучения и существенно влияют на производительность модели:\n",
    "\n",
    "- *Архитектура сети:*\n",
    "  - Количество скрытых слоев и нейронов в каждом слое.  \n",
    "  - Структура сети, используемые слои.\n",
    "  - Функции активации и, если есть, их параметры.\n",
    "\n",
    "- *Оптимизатор и скорость обучения (Learning Rate):* \n",
    "  Слишком высокий learning rate может привести к нестабильному обучению, а слишком низкий — к медленной сходимости. Может использоваться динамический шаг градиентного спуска, расписание, ранняя остановка.\n",
    "\n",
    "- *Размер батча (Batch Size):*\n",
    "  Количество примеров, используемых для одного обновления весов. Больший batch size может дать более стабильную оценку градиента, но требует больше оперативной памяти.\n",
    "\n",
    "- *Количество эпох (Epochs):*\n",
    "  Число полных проходов по обучающему набору данных. В общем случае эпох должно быть достаточно для установления постоянства по функции потерь.\n",
    "\n",
    "- *Методы регуляризации:*\n",
    "  Такие как L1/L2 (коэффициенты) регуляризация и dropout (вероятность), помогают уменьшить переобучение, сохраняя обобщающую способность модели.\n",
    "\n",
    "Подбор этих гиперпараметров зачастую требует экспериментов и может быть оптимизирован с помощью методов поиска и концепции кросс-валидации (Grid Search, Random Search, Bayesian Optimization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://towardsdatascience.com/wp-content/uploads/2022/09/1_9coeJ4OSPqAjiKLcQqiew.png\" alt=\"Описание изображения\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_units, dropout_rate, num_classes):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_units)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_units, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.2, 0.5)\n",
    "    hidden_units = trial.suggest_int(\"hidden_units\", 64, 256)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    dataset = torchvision.datasets.MNIST(\n",
    "        root=\"./data\", train=True, download=True, transform=transform\n",
    "    )\n",
    "    \n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    model = SimpleMLP(input_size=28 * 28, hidden_units=hidden_units,\n",
    "                      dropout_rate=dropout_rate, num_classes=10)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    epochs = 3\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                val_loss += loss.item() * data.size(0)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += pred.eq(target).sum().item()\n",
    "                total += data.size(0)\n",
    "        val_loss /= total\n",
    "        accuracy = correct / total\n",
    "\n",
    "        trial.report(val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "print(\"Лучший результат:\")\n",
    "best_trial = study.best_trial\n",
    "print(f\"Validation Loss: {best_trial.value:.4f}\")\n",
    "print(\"Лучшие гиперпараметры:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"{key}: {round(value, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучаемые параметры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучаемые параметры** — это те числовые значения в модели, которые обновляются в процессе обучения с целью минимизации функции потерь (ошибки). В нейронных сетях к таким параметрам относятся:\n",
    "- **Веса (Weights):** Коэффициенты, умножаемые на входные данные.\n",
    "- **Смещения (Biases):** Константные слагаемые, добавляемые к результату линейного преобразования.\n",
    "\n",
    "Описанные выше типы слоев позволяют решать различные типы задач, за счет оптимизации этих параметров. Это как бы дает \"степени свободы\" для модели.\n",
    "\n",
    "Пример:\n",
    "Для одного нейрона с входными данными $ x $, весами $ \\mathbf{w} $ и смещением $ b $ предсказание вычисляется по формуле:\n",
    "$$\n",
    "a = \\sigma\\left(\\langle \\mathbf{w}, x \\rangle + b\\right),\n",
    "$$\n",
    "где $ \\sigma $ — функция активации. \n",
    "В процессе обучения цель заключается в нахождении таких значений $ \\mathbf{w} $ и $ b $, при которых функция потерь $ \\mathcal{L} $ (например, среднеквадратичная ошибка) минимальна:\n",
    "$$\n",
    "\\min_{\\mathbf{w},\\, b} \\; \\mathcal{L}(y, f(x; \\mathbf{w}, b)).\n",
    "$$\n",
    "\n",
    "Для обучаемых параметров есть два основных этапа:\n",
    "- *Инициализация*\n",
    "- *Обновление*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Виды инициализации параметров\n",
    "Правильная инициализация параметров — важный аспект, влияющий на скорость сходимости и качество обучения. В статьях, презентующих новые виды слове или функций активации ему обычно посвящают теоретический блок. Однако существуют общие подходы:\n",
    "\n",
    "**Инициализация случайными значениями**\n",
    "- *Uniform Initialization:* Весам присваиваются значения, равномерно распределённые в некотором интервале, например, $[-a, a]$.\n",
    "- *Normal Initialization:* Значения весов берутся из нормального распределения с нулевым средним и заранее заданной дисперсией.\n",
    "\n",
    "**Инициализация с учетом размеров слоев**\n",
    "- *Xavier Initialization:* \n",
    "  - Разработана для эффективного распространения сигналов в сети с симметричными функциями активации (например, tanh, sigmoid). \n",
    "  - Весам присваиваются значения из распределения с дисперсией, зависящей от количества входов и выходов:\n",
    "  $$\n",
    "  \\text{Var}(w) = \\frac{2}{n_{in} + n_{out}}.\n",
    "  $$\n",
    "  - Xavier Uniform Initialization:\n",
    "    $$\n",
    "    W \\sim U\\left(-\\sqrt{\\frac{6}{n_{\\text{in}} + n_{\\text{out}}}},\\; \\sqrt{\\frac{6}{n_{\\text{in}} + n_{\\text{out}}}}\\right).\n",
    "    $$\n",
    "  - Xavier Normal Initialization:\n",
    "    $$\n",
    "    W \\sim \\mathcal{N}\\left(0,\\; \\sqrt{\\frac{2}{n_{\\text{in}} + n_{\\text{out}}}}\\right).\n",
    "    $$\n",
    "- *Kaiming Initialization:*\n",
    "  - Адаптирована для слоев с функцией активации ReLU.\n",
    "  - Весам присваиваются значения с дисперсией: $ \\text{Var}(w) = \\frac{2}{n_{in}} $, что помогает избежать проблем с затуханием или \"взрывом\" градиентов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.doc.ic.ac.uk/~nuric/posts/teaching/imperial-college-machine-learning-neural-networks/cover.gif\" alt=\"Описание изображения\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TensorFlow Playground](https://playground.tensorflow.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dim=256, num_classes=10):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def initialize_weights(model, init_type):\n",
    "    \"\"\"\n",
    "    Функция инициализации весов для модели.\n",
    "    \n",
    "    Аргументы:\n",
    "      model (torch.nn.Module): модель для инициализации весов.\n",
    "      init_type (str): тип инициализации. Возможные варианты:\n",
    "        - \"xavier_uniform\"\n",
    "        - \"kaiming_normal\"\n",
    "    \"\"\"\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            if init_type == \"xavier_uniform\":\n",
    "                init.xavier_uniform_(m.weight)\n",
    "            elif init_type == \"kaiming_normal\":\n",
    "                init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "            else:\n",
    "                raise ValueError(\"Неизвестный тип инициализации\")\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, optimizer, criterion, device, num_epochs=5):\n",
    "    \"\"\"\n",
    "    Функция обучения модели.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        running_loss = 0.0\n",
    "        total = 0\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * data.size(0)\n",
    "            total += data.size(0)\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_losses.append(epoch_loss)\n",
    "    return epoch_losses\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "subset_indices = np.arange(1000)\n",
    "dataset = Subset(dataset, subset_indices)\n",
    "train_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "model_xavier = SimpleMLP().to(device)\n",
    "initialize_weights(model_xavier, init_type=\"xavier_uniform\")\n",
    "optimizer_xavier = optim.Adam(model_xavier.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(\"Обучение модели с инициализацией Xavier Uniform:\")\n",
    "losses_xavier = train_model(model_xavier, train_loader, optimizer_xavier, criterion, device, num_epochs)\n",
    "\n",
    "model_kaiming = SimpleMLP().to(device)\n",
    "initialize_weights(model_kaiming, init_type=\"kaiming_normal\")\n",
    "optimizer_kaiming = optim.Adam(model_kaiming.parameters(), lr=1e-3)\n",
    "print(\"Обучение модели с инициализацией Kaiming Normal:\")\n",
    "losses_kaiming = train_model(model_kaiming, train_loader, optimizer_kaiming, criterion, device, num_epochs)\n",
    "\n",
    "epochs = np.arange(1, num_epochs+1)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs, losses_xavier, \"o-\", label=\"Xavier Uniform\")\n",
    "plt.plot(epochs, losses_kaiming, \"s-\", label=\"Kaiming Normal\")\n",
    "plt.xlabel(\"Эпоха\")\n",
    "plt.ylabel(\"Средняя Loss\")\n",
    "plt.title(\"Сравнение сходимости модели с разной инициализацией весов\")\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Автоматическое дифференцирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Автоматическое дифференцирование** — это метод вычисления производных (градиентов) функции, с использованием алгоритмов, которые реализуют правило цепочки (производная сложной функции, chain rule).\n",
    "\n",
    "Ключевые моменты:\n",
    "- *Правило цепочки:* Автодифференцирование \"распространяет\" вычисления производных через весь вычислительный граф, начиная с выходного слоя и двигаясь к входным данным (обратный режим), или наоборот (прямой режим).\n",
    "- *Виды:*\n",
    "  - **Прямой режим (Forward Mode):** Эффективен, когда число входов невелико по сравнению с числом выходов.\n",
    "  - **Обратный режим (Reverse Mode):** Чаще используется в нейронных сетях, так как число выходов, как правило, мало, а число параметров велико. Именно обратное распространение ошибки (backpropagation) является применением автодифференцирования.\n",
    "- *Преимущества:*\n",
    "  - Производные вычисляются с точностью машинного представления.\n",
    "  - Вычисление градиента происходит за время, сравнимое с временем расчета функции, независимо от размерности входов.\n",
    "  - Автоматизация вычислений.\n",
    "\n",
    "  Метод не подвержен неусточивости, накоплению ошибок округления и неэффективному представлению в памяти в сравнении с конечными разностями или символьным дифференцированием."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://alexander-schiendorfer.github.io/images/backprop/nnet-vanilla.gif\" alt=\"Описание изображения\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Пример: Сравнение автодифференцирования и аналитического вычисления производной\n",
    "\n",
    "В этом примере:\n",
    "  - Определяется функция f(x) = x^3 + 2*x^2.\n",
    "  - Вычисляется аналитическая производная f'(x) = 3*x^2 + 4*x.\n",
    "  - С помощью механизма автодифференцирования в PyTorch вычисляется\n",
    "    градиент этой же функции.\n",
    "  - Результаты сравниваются на множестве точек и отображаются на графике.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def f(x):\n",
    "    return x**3 + 2*x**2\n",
    "\n",
    "def analytic_derivative(x):\n",
    "    return 3*x**2 + 4*x\n",
    "\n",
    "xs = torch.linspace(-5, 5, 100, requires_grad=True)\n",
    "ys = f(xs)\n",
    "\n",
    "gradients = torch.autograd.grad(ys, xs, grad_outputs=torch.ones_like(ys), create_graph=True)[0]\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "xs_np = xs.detach().numpy()\n",
    "gradients_np = gradients.detach().numpy()\n",
    "plt.plot(xs_np, gradients_np, label=\"Производная (Autograd)\")\n",
    "\n",
    "analytic_np = analytic_derivative(xs_np)\n",
    "plt.plot(xs_np, analytic_np, label=\"Аналитическая производная\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Производная\")\n",
    "plt.title(\"Сравнение автодифференцирования и аналитического вычисления производной\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки для нейронных сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существуют несколько ключевых библиотек для разработки нейронных сетей на Python, каждая из которых имеет свои особенности и преимущества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow\n",
    "**TensorFlow** – это фреймворк, разработанный Google, который изначально основан на концепции статических вычислительных графов. Начиная с версии 2.x, активно используется режим \"eager execution\" - это режим, при котором операции выполняются немедленно при вызове, а не строятся в виде статического графа вычислений.\n",
    "\n",
    "Особенности:\n",
    "- Поддерживает как низкоуровневое программирование с построением вычислительных графов, так и высокоуровневое API через Keras - изначальной другой библиотеки, которая теперь входит в состав TF.\n",
    "- Позволяет работать как на CPU, так и на GPU и TPU, что способствует ускорению обучения для больших моделей.\n",
    "- Имеет TensorBoard для визуализации, TensorFlow Serving для развертывания.\n",
    "- Надежный инструмент, качественно поддерживаемый Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow numpy==1.26.0 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class SimpleTFModel(tf.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, name=None):\n",
    "        super(SimpleTFModel, self).__init__(name=name)\n",
    "        self.w1 = tf.Variable(tf.random.normal([input_dim, hidden_dim]), name=\"w1\")\n",
    "        self.b1 = tf.Variable(tf.zeros([hidden_dim]), name=\"b1\")\n",
    "        self.w2 = tf.Variable(tf.random.normal([hidden_dim, output_dim]), name=\"w2\")\n",
    "        self.b2 = tf.Variable(tf.zeros([output_dim]), name=\"b2\")\n",
    "\n",
    "    def __call__(self, x):\n",
    "        hidden = tf.nn.relu(tf.matmul(x, self.w1) + self.b1)\n",
    "        output = tf.matmul(hidden, self.w2) + self.b2\n",
    "        return output\n",
    "\n",
    "input_dim = 5\n",
    "hidden_dim = 10\n",
    "output_dim = 2\n",
    "\n",
    "model = SimpleTFModel(input_dim, hidden_dim, output_dim)\n",
    "x = tf.random.normal([3, input_dim])\n",
    "y = model(x)\n",
    "print(\"Выход модели TensorFlow:\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras\n",
    "**Keras** – это высокоуровневый API для построения нейронных сетей. Сейчас Keras интегрирован в TensorFlow и является его стандартным интерфейсом для быстрой сборки моделей.\n",
    "\n",
    "Особенности:\n",
    "- Обладает интуитивно понятным синтаксисом.\n",
    "- Несмотря на высокоуровневый подход, позволяет достаточно подробно контролировать параметры модели.\n",
    "- Богатая документация и обширное сообщество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "\n",
    "\n",
    "def build_keras_model(input_dim, hidden_dim, output_dim):\n",
    "    model = Sequential([\n",
    "        layers.Dense(hidden_dim, activation='relu', \n",
    "                     input_shape=(input_dim,)),\n",
    "        layers.Dense(output_dim)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "input_dim = 5\n",
    "hidden_dim = 10\n",
    "output_dim = 2\n",
    "\n",
    "model = build_keras_model(input_dim, hidden_dim, output_dim)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "x = np.random.randn(3, input_dim)\n",
    "y = model(x)\n",
    "print(\"Выход модели Keras:\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch\n",
    "**PyTorch** – это библиотека, разработанная Facebook (Meta, запрещена в РФ), с интуитивно понятной архитектурой и динамическим вычислительным графом.\n",
    "\n",
    "Особенности:\n",
    "- Каждый шаг вычислений производится \"на лету\", что позволяет легко изменять модель.\n",
    "- Проста в освоении и хорошо интегрирована с Python.\n",
    "- Наиболее широко используется в академических исследованиях, что способствует быстрому внедрению новых идей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimplePyTorchModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimplePyTorchModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_dim = 5\n",
    "hidden_dim = 10\n",
    "output_dim = 2\n",
    "model = SimplePyTorchModel(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "x = torch.randn(3, input_dim)\n",
    "y = model(x)\n",
    "print(\"Выход модели PyTorch:\")\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
