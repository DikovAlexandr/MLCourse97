{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция 1: Задачи машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Машинное обучение (ML) - это область искусственного интеллекта, которая разрабатывает алгоритмы и модели, позволяющие программам изучать закономерности в данных и принимать решения на основе полученного опыта. \n",
    "\n",
    "В основе ML лежит идея: вместо того чтобы задавать каждому шагу алгоритма **точную инструкцию**, мы предоставляем системе данные, и она самостоятельно находит **универсальные правила** для решения поставленных задач.\n",
    "\n",
    "Для описания систем часто выделают два подхода: \n",
    "- rule-based - когда поведение определяется набором правил или уравнений.\n",
    "- [data-driven](https://practicum.yandex.ru/blog/chto-takoe-data-driven-podhod/) - когда описание поведения составляется на основе данных и закономерности выявляются без явного задания правил.\n",
    "\n",
    "В контексте машинного обучения используется именно второй подход, относительно него строятся задачи и модели, нацеленные именно на выявления неявных закономерностей в привычных нам данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/rulebased_datadriven.jpg\" alt=\"Подходы\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если рассматривать задачи с точки зрения процесса обучения, методы могут быть разделены на три категории:\n",
    "- **Обучение с учителем (Supervised Learning):** при наличии разметки - каждому входному примеру сопоставляется метка или целевое значение.\n",
    "- **Обучение без учителя (Unsupervised Learning):** данные не размечены, и задача заключается в выявлении скрытой структуры или закономерностей в данных.\n",
    "- **Обучение с подкреплением (Reinforcement Learning, RL):** добавлен механизм влияния на процесс обучения модели факторов из \"окружающего мира\".\n",
    "\n",
    "Это наиболее распространенное разделение, однако в индустрии используются и более современные подходы:\n",
    "- **Обучение с частичным привлечением учителя (Semi-Supervised Learning):** используется небольшое количество размеченных примеров и большое количество неразмеченных, модель учится использовать неразмеченные данные для улучшения качества предсказания.\n",
    "- **Обучение с самоконтролем (Self-Supervised Learning, SSL)**: особый случай обучения без учителя, где метки генерируются автоматически на основе самих данных, то есть используется закономерности в них, не требующие дополнительной разметки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/supervised_learning.jpg\" alt=\"Типы обучения\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если рассматривать задачи с точки зрения конечной цели, можно выделить две основные категории:\n",
    "- **Дискриминативные задачи:** направлены на разделение данных, предсказание меток или регрессию. Примерами являются классификация и регрессия. Моделируют зависимость вида $ p(y \\mid x) $. Цель таких моделей - предсказывать метки или значения на основе входных признаков, не пытаясь смоделировать сам процесс генерации данных.\n",
    "- **Генеративные задачи:** целятся в изучение и моделирование полного распределения данных, что позволяет генерировать новые, «реалистичные» примеры, аналогичные исходным. Моделируют совместное распределение $ p(x, y) $ (или просто $ p(x) $ в случае отсутствия меток) и, таким образом, способны генерировать новые данные, похожие на исходные, а также могут использоваться для решения задач классификации через вычисление условных вероятностей. Примеры — генерация текста, изображений, музыки и т.д.\n",
    "\n",
    "В первую очередь будут рассмотрены постановки основных типов дискреминативных задач машинного обучения, а именно: **классификацию**, **регрессию** и **кластеризацию**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/ml_task_types.png\" alt=\"Типы задач\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация\n",
    "\n",
    "##### Суть задачи\n",
    "Классификация применяется, когда необходимо распределить объекты по заранее определённым категориям. В обучающей выборке каждый объект сопровождается меткой класса, что позволяет модели изучить характерные особенности каждого класса и впоследствии использовать их для распознавания новых данных.\n",
    "\n",
    "##### Постановка задачи\n",
    "Допустим, у нас имеется обучающая выборка:\n",
    "$$\n",
    "\\mathcal{D} = \\{ (\\mathbf{x}_i, y_i) \\}_{i=1}^N,\n",
    "$$\n",
    "где $\\mathbf{x}_i \\in \\mathbb{R}^d$ — вектор признаков, а $y_i \\in \\{1, 2, \\dots, K\\}$ — метка класса.\n",
    "\n",
    "Цель построить функцию $f: \\mathbb{R}^d \\to \\{1,\\dots,K\\}$, такую что для **новых** точек $\\mathbf{x}$ она правильно предсказывает их класс.\n",
    "\n",
    "##### Основные типы классификации\n",
    "- **Бинарная классификация** ($K=2$) — два класса.\n",
    "- **Мультиклассовая классификация** ($K>2$) — более двух категорий.\n",
    "- **Multi-label классификация** — один объект может принадлежать сразу нескольким классам одновременно.\n",
    "\n",
    "##### Основные модели\n",
    "- **Логистическая регрессия**\n",
    "- **Наивный байес**\n",
    "- **Метод опорных векторов (SVM)**\n",
    "- **Деревья решений и ансамбли**\n",
    "- **k-ближайших соседей (КNN)**\n",
    "- **Нейронные сети**\n",
    "\n",
    "##### Примеры\n",
    "- **Распознавание рукописных цифр:** например, набор данных MNIST, где изображенные цифры нужно отнести к соответствующим числам.\n",
    "- **Фильтрация спама:** классификация электронных писем на \"спам\" и \"не спам\".\n",
    "- **Распознавание образов:** определение типа объекта на изображении (кот, собака, автомобиль и т.д.).\n",
    "\n",
    "> Задача классификации в контексте линейных моделей рассматривается в подробнее в [учебнике](https://education.yandex.ru/handbook/ml/article/linear-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/classification.png\" alt=\"Классификация\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регрессия\n",
    "\n",
    "##### Суть задачи\n",
    "Регрессия направлена на предсказание непрерывной величины. Здесь модель изучает зависимость между входными признаками и непрерывным выходом, пытаясь минимизировать ошибку между предсказанными и истинными значениями.\n",
    "\n",
    "##### Постановка задачи\n",
    "Рассмотрим обучающую выборку вида:\n",
    "$$\n",
    "\\mathcal{D} = \\{ (\\mathbf{x}_i, y_i) \\}_{i=1}^N,\n",
    "$$\n",
    "где $\\mathbf{x}_i \\in \\mathbb{R}^d$ — вектор признаков, а $y_i \\in \\mathbb{R}$ — непрерывное значение, которое требуется предсказать (тоже может быть многомерным, $\\mathbb{R}^m$).\n",
    "\n",
    "Цель построить функцию $f: \\mathbb{R}^d \\to \\mathbb{R}$ (или $\\mathbb{R}^m$), так чтобы предсказания $\\hat y = f(\\mathbf{x})$ были как можно ближе к истинным $y$.\n",
    "\n",
    "##### Основные модели\n",
    "- **Линейная регрессия**\n",
    "- **Полиномиальная регрессия**\n",
    "- **Регуляризованная регрессия**\n",
    "- **Метод опорных векторов для регрессии (SVR)**\n",
    "- **Деревья решений и ансамбли**\n",
    "- **k-ближайших соседей (КNN)**\n",
    "- **Нейронные сети**\n",
    "\n",
    "##### Примеры\n",
    "- **Прогнозирование цен:** например, оценка рыночной стоимости недвижимости или прогнозирование цен акций.\n",
    "- **Физические прогнозы:** определение физических параметров системы по различным показателям.\n",
    "- **Временные ряды:** прогнозирование на основе исторических данных.\n",
    "\n",
    "> Задача регрессии в контексте линейных моделей рассматривается в подробнее в [учебнике](https://education.yandex.ru/handbook/ml/article/linear-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/regression.png\" alt=\"Регрессия\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кластеризация\n",
    "\n",
    "##### Суть задачи\n",
    "Кластеризация относится к методам обучения без учителя. Здесь задача состоит в **автоматическом разделении** набора неразмеченных объектов на группы (кластеры) по принципу максимального внутригруппового сходства и минимального межгруппового сходства. Кластеризация позволяет автоматически выявлять скрытые структуры и паттерны в данных.\n",
    "\n",
    "##### Постановка задачи\n",
    "Пусть имеется набор объектов без меток:\n",
    "$$\n",
    "\\mathcal{D} = \\{ \\mathbf{x}_i \\}_{i=1}^N, \\quad \\mathbf{x}_i \\in \\mathbb{R}^d.\n",
    "$$\n",
    "Задача кластеризации заключается в разделении объектов на $K$ групп, таких что объекты внутри одной группы максимально похожи друг на друга, а объекты разных групп — существенно различаются. При этом в части методов $K$ не задается наперед.\n",
    "\n",
    "Требуется найти функцию $g\\colon\\mathbb{R}^d\\to\\{1,2,\\dots,K\\}$, которая присваивает каждому объекту номер кластера, при этом для объектов одного кластера расстояния (или меры несхожести) между признаковыми векторами минимальны, а для объектов разных кластеров — максимальны. В ряде методов число кластеров $K$ задаётся заранее, в других оно определяется автоматически.\n",
    "\n",
    "##### Типы кластеризации\n",
    "- **Плоская (partitional):** сразу строится разбиение на заданное число $K$ кластеров.\n",
    "- **Иерархическая:** строится дерево вложенных кластеров.\n",
    "- **Плотностная:** кластеры определяются как области высокой плотности точек, число кластеров не задаётся заранее.\n",
    "- **Нечетная (fuzzy) кластеризация:** объект может частично принадлежать сразу нескольким кластерам.\n",
    "\n",
    "##### Основные модели\n",
    "- **k-means**\n",
    "- **Agglomerative Clustering**\n",
    "- **DBSCAN**\n",
    "- **Spectral Clustering**\n",
    "- **Gaussian Mixture Models (GMM)**\n",
    "\n",
    "##### Примеры\n",
    "- **Сегментация клиентов:** выделение групп потребителей с похожим поведением или интересами.\n",
    "- **Группировка документов:** автоматическое распределение текстов по темам.\n",
    "- **Обнаружение аномалий:** обнаружение выбросов или аномальных объектов в наборе данных.\n",
    "\n",
    "> Подробнее про методы и задачу кластеризации в целом можно прочитать в [учебнике](https://education.yandex.ru/handbook/ml/article/klasterizaciya)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/clustering.jpg\" alt=\"Кластеризация\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практические примеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "dir(sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [2, 3]]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(multi_class='ovr', \n",
    "                                solver='lbfgs', \n",
    "                                max_iter=200)\n",
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                        np.arange(y_min, y_max, 0.01))\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "Z = classifier.predict(grid)\n",
    "Z = Z.reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Set1)\n",
    "plt.scatter(\n",
    "    X[:, 0], X[:, 1],\n",
    "    c=y, edgecolors='k', cmap=plt.cm.Set1,\n",
    "    s=40, linewidth=0.5\n",
    ")\n",
    "plt.xlabel('Petal length')\n",
    "plt.ylabel('Petal width')\n",
    "plt.title('Iris Classification with Logistic Regression')\n",
    "plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y, label='Data', s=30, edgecolors='k')\n",
    "sorted_idx = X[:, 0].argsort()\n",
    "plt.plot(\n",
    "    X[sorted_idx], y_pred[sorted_idx],\n",
    "    color='red', linewidth=2, label='Regression line'\n",
    ")\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Target')\n",
    "plt.title('Linear Regression Fit')\n",
    "plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кластеризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_true = make_blobs(n_samples=300, centers=3, cluster_std=1.0,\n",
    "                       random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "y_kmeans = kmeans.fit_predict(X)\n",
    "centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(\n",
    "    X[:, 0], X[:, 1],\n",
    "    c=y_kmeans, s=60, cmap='viridis', edgecolors='k', alpha=0.8,\n",
    "    label='Clusters'\n",
    ")\n",
    "plt.scatter(\n",
    "    centers[:, 0], centers[:, 1],\n",
    "    c='red', s=250, marker='X', edgecolors='k', linewidth=1.5,\n",
    "    label='Centroids'\n",
    ")\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('KMeans Clustering')\n",
    "plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
