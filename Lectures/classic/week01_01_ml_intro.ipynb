{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция 1.1: Задачи машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Машинное обучение (ML) – это область искусственного интеллекта, которая разрабатывает алгоритмы и модели, позволяющие программам изучать закономерности в данных и принимать решения на основе полученного опыта. \n",
    "\n",
    "В основе ML лежит идея: вместо того чтобы задавать каждому шагу алгоритма **точную инструкцию**, мы предоставляем системе данные, и она самостоятельно находит **универсальные правила** для решения поставленных задач.\n",
    "\n",
    "Для описания систем часто выделают два подхода: \n",
    "- **rule-based** – когда поведение определяется набором правил или уравнений.\n",
    "- [**data-driven**](https://practicum.yandex.ru/blog/chto-takoe-data-driven-podhod/) - когда описание поведения составляется на основе данных и закономерности выявляются без явного задания правил.\n",
    "\n",
    "В контексте машинного обучения используется именно второй подход, относительно него строятся задачи и модели, нацеленные на выявления неявных закономерностей в привычных нам данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../images/rulebased_datadriven.jpg\" alt=\"Подходы\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основной способ достижения цели – обучение – автоматический процесс настройки параметров модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../images/ml_pipeline.png\" alt=\"Обучение\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если рассматривать задачи с точки зрения процесса обучения, методы могут быть разделены на три категории:\n",
    "- **Обучение с учителем (Supervised Learning):** при наличии разметки – каждому входному примеру сопоставляется метка или целевое значение.\n",
    "- **Обучение без учителя (Unsupervised Learning):** данные не размечены, и задача заключается в выявлении скрытой структуры или закономерностей в данных.\n",
    "- **Обучение с подкреплением (Reinforcement Learning, RL):** добавлен механизм влияния на процесс обучения модели факторов из \"окружающего мира\".\n",
    "\n",
    "Это наиболее распространенное разделение, однако иногда полезными оказываются и другие подходы:\n",
    "- **Обучение с частичным привлечением учителя (Semi-Supervised Learning):** используется небольшое количество размеченных примеров и большое количество неразмеченных, модель учится использовать неразмеченные данные для улучшения качества предсказания.\n",
    "- **Обучение с самоконтролем (Self-Supervised Learning, SSL)**: особый случай обучения без учителя, где метки генерируются автоматически на основе самих данных, то есть используется закономерности в них, не требующие дополнительной разметки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../images/supervised_learning.jpg\" alt=\"Типы обучения\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку на практике приходится работать с данными различной природы и объема, полезно разделять алгоритмы машинного обучения по масштабируемости (по аналогии с пространственной сложностью обычных алгоритмов):\n",
    "- **Параметрические модели**: имеют фиксированное, заранее заданное количество параметров, которое не зависит от размера данных. Обучение заключается в подборе значений этих параметров.\n",
    "- **Непараметрические модели**: сложность модели растёт с увеличением объёма данных, так как они не фиксируют жёсткую функциональную форму, а \"запоминают\" данные или адаптируют свою структуру под них."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если рассматривать задачи с точки зрения конечной цели, можно выделить две основные категории:\n",
    "- **Дискриминативные задачи:** направлены на разделение данных, предсказание меток или регрессию. Примерами являются классификация и регрессия. Моделируют зависимость вида $ p(y \\mid x) $. Цель таких моделей – предсказывать метки или значения на основе входных признаков, не пытаясь смоделировать сам процесс генерации данных.\n",
    "- **Генеративные задачи:** целятся в изучение и моделирование полного распределения данных, что позволяет генерировать новые, «реалистичные» примеры, аналогичные исходным. Моделируют совместное распределение $ p(x, y) $ (или просто $ p(x) $ в случае отсутствия меток) и, таким образом, способны генерировать новые данные, похожие на исходные, а также могут использоваться для решения задач классификации через вычисление условных вероятностей.\n",
    "\n",
    "В первую очередь будут рассмотрены постановки основных типов дискреминативных задач машинного обучения, а именно: **классификация**, **регрессия** и **кластеризация**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../images/ml_task_types.png\" alt=\"Типы задач\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы уже поняли, модели (или алгоритмы) машинного обучения позволяют решать задачи на основании некоторого процесса обучения над данными. Важно понимать, что помимо прочих особенностей и вариативности этапа обучения, которые подробнее будут рассмотрены далее, есть также классификация по стратегии обучения:\n",
    "\n",
    "- **Пакетное обучение (Batch/Offline)** – модель обучается сразу на всей полной выборке данных. Именно оно рассматривается в курсе, ввиду куда большей распространенности.\n",
    "- **Инкрементальное обучение (Incremental/Online)** – модель дообучается постепенно, по мере поступления новых данных небольшими порциями. Подробнее можно посмотреть в [презентации](http://www.machinelearning.ru/wiki/images/1/17/Voron-ML-incremental-slides.pdf).\n",
    "\n",
    "> По аналогии, обученная модель после внедрения в сервис может также работать в различных режимах:\n",
    "> - **Пакетный (Offline)** – модель запускается по расписанию для обработки накопленных данных.\n",
    "> - **Микропакетный (Near-online)** – предсказание выполняется часто, но не мгновенно, обрабатывая данные небольшими пачками.\n",
    "> - **Поточный (Online)** – предсказание выполняется синхронно, по запросу, модель возвращает ответ в реальном времени.\n",
    "> \n",
    "> Это относится уже не столько к машинному обучения, сколько к деталям реализации конкретного сервиса, однако заслуживает упоминания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обладая широким набором инструментов и возможных постановок решаемых задач, можно также выделить основные области применения алгоритмов машинного обучения:\n",
    "\n",
    "- **General ML (Классический ML)** – охватывает фундаментальные алгоритмы и модели, которые являются универсальными и могут быть применены к данным любой природы без узкоспециализированной адаптации.\n",
    "- **NLP (Обработка естественного языка)** – направлен на работу с текстом, понимание, интерпретацию и генерацию человеческого языка.\n",
    "- **CV (Компьютерное зрение)** – направлен на понимание визуальную информации, анализ изображений и видео, распознавание объектов и сцен.\n",
    "- **RecSys (Рекомендательные системы)** – прогнозировании предпочтений пользователей и фильтрации/поиска информации.\n",
    "- **PIML/SciML (Научный ML)** – использует машинное обучение для решения научных задач, часто комбинируя данные с известными физическими законами для моделирования сложных систем и открытия новых закономерностей/решений.\n",
    "- **Robotics (Робототехника)** – занимается созданием алгоритмов для роботов, позволяя им воспринимать окружающую среду, планировать движения и автономно выполнять задачи в реальном мире.\n",
    "\n",
    "> Есть также работа со звуком, например голосовой ввод или синтез речи. Это направление редко выделяется как отдельное и чаще существует на стыке NLP и CV, используя дополнительно численные методы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Кто этим занимается?\n",
    "\n",
    "Для обеспечения работы описанного процесса зачастую необходимо большое количество специалистов, каждый из которых имеет свою, конкретную специализацию:\n",
    "\n",
    "- Product Manager – определяет решаемую проблему\n",
    "- Data Analyst – исследует существующие данные\n",
    "- Data Engineer – организует процессы поставки данных\n",
    "- Machine Learning Engineer – определяет как разработать модель, подходящую для реального использования\n",
    "- Machine Learning Researcher – проводить исследование, разрабатывает новое лучшее решение\n",
    "\n",
    "Всем этим работникам необходима также тесная коммуникация с командами разработки (Frontend, Backend, Mobile, DevOps), именно в их процессы встраиваются ML-компоненты.\n",
    "\n",
    "Часто DA, DE, MLE, MLR называют общим термином Data Scientist (DS) - по итогу за этим термином может скрываться любой набор навыков, которые ожидает видеть работодатель. Но это уже [проблемы](https://www.youtube.com/watch?v=Cs3ae65tmKA&t=247s) рынка труда.\n",
    "\n",
    "Курс направлен на подготовку MLE или MLR и дает поверхностные знания в других направлениях. Непосредственно MLE обычно занимается следующими задачами:\n",
    "1. Выбором архитектуры (математической модели)\n",
    "2. Выбором гиперпараметров модели\n",
    "3. Определением способа настройки параметров модели\n",
    "4. Обучением моделей\n",
    "5. Оценкой качества моделей\n",
    "6. Сопоставлением различных моделей\n",
    "7. Продуктивизация, то есть внедрение модели в реальные процессы с учетом их метрик, по типу [SLA](https://cloud.google.com/blog/products/devops-sre/sre-fundamentals-slis-slas-and-slos)\n",
    "\n",
    "Важно понимать, что обязанности специалистов могут отличаться в зависимости от компании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Типовые этапы и понятие pipeline\n",
    "\n",
    "Прежде чем переходить к конкретным задачам, рассмотрим несколько максимально общих терминов и этапов работы с данными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../images/ml_solution.png\" alt=\"Этапы решения задач\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самым значимым отличием решения заданий в университете является присутствие этапа понимания бизнеса, который часто опускается в академической среде. Так, задача от бизнеса может формулироваться общими словами и требовать широких знаний и опыта для перевода ее на язык ML.\n",
    "\n",
    "После того как задача поставлена, можно проводить подготовку модели. Данная задача может быть также разбита на этапы, каждый и которых часто является отдельной небольшой задачей. В общем случае шаги следующие: \n",
    "- загрузка данных\n",
    "- предобработка\n",
    "- обучение или использование предобученной модели\n",
    "- пост-обработка\n",
    "- оценка результатов\n",
    "\n",
    "> Валидация может отличаться в зависимости от данных и используемого ML-подхода, но чаще всего она осуществляется путем расчета метрик качества на отложенной выборке (моделирование ситуации \"неизвестного будущего\" для модели). То, как именно должны быть отложены данные и какие метрики необходимо посчитать сильно зависит от задачи и требует экспертизы, а иногда и общей эрудиции.\n",
    "\n",
    "Само обучение, как мы узнаем далее, может быть либо дообучением, либо переобучением модели с нуля. В курсе будет рассмотрен первый подход и его вариации, но для примеров чаще будет использован второй. Он обычно реализуется следующим образом:\n",
    "- сначала имеющаяся выборка разбивается на тренировочную, валидационную и тестовую\n",
    "- модель учится на тренировочной выборке, а валидационная используется для оценки качества модели\n",
    "- поскольку у модели есть гиперпараметры, от которых значительно зависит итоговое качество, результаты оценки на валидации используется для их подбора\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>Замечание:</b> Выбирая модель с использованием результатов на валидационной выборке, мы допускаем <b>утечку данных</b>, при этом даже не проводя обучения модели на них. Работа с данными будет подробнее рассмотрена в следующем <a href=\"week01_02_data.ipynb\" target=\"_blank\">ноутбуке</a>\n",
    "</div>\n",
    "\n",
    "- получаем итоговые метрики модели на тестовых данных, которые специально отложены для этой конечной оценки\n",
    "- модель с подобранными гиперпараметрами с нуля обучается на всей выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../images/train_test_val.png\" alt=\"Разбиение данных\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобравшись с основной идеи работы с данными можно переходить в постановке и формализации конкретных задач."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация\n",
    "\n",
    "##### Суть задачи\n",
    "Классификация применяется, когда необходимо распределить объекты по заранее определённым категориям. В обучающей выборке каждый объект сопровождается меткой класса, что позволяет модели изучить характерные особенности каждого класса и впоследствии использовать их для распознавания новых данных.\n",
    "\n",
    "##### Постановка задачи\n",
    "Допустим, у нас имеется обучающая выборка:\n",
    "$$\n",
    "\\mathcal{D} = \\{ (\\mathbf{x}_i, y_i) \\}_{i=1}^N,\n",
    "$$\n",
    "где $\\mathbf{x}_i \\in \\mathbb{R}^d$ – вектор признаков, а $y_i \\in \\{1, 2, \\dots, K\\}$ – метка класса.\n",
    "\n",
    "Цель построить функцию $f: \\mathbb{R}^d \\to \\{1,\\dots,K\\}$, такую что для **новых** точек $\\mathbf{x}$ она правильно предсказывает их класс.\n",
    "\n",
    "##### Основные типы классификации\n",
    "- **Бинарная классификация** ($K=2$) – два класса.\n",
    "- **Мультиклассовая классификация** ($K>2$) – более двух категорий.\n",
    "- **Multi-label классификация** – один объект может принадлежать сразу нескольким классам одновременно.\n",
    "\n",
    "##### Основные модели\n",
    "- **Логистическая регрессия**\n",
    "- **Наивный байес**\n",
    "- **Метод опорных векторов (SVM)**\n",
    "- **Деревья решений и ансамбли**\n",
    "- **k-ближайших соседей (КNN)**\n",
    "- **Нейронные сети**\n",
    "\n",
    "##### Примеры\n",
    "- **Распознавание рукописных цифр:** например, набор данных MNIST, где изображенные цифры нужно отнести к соответствующим числам.\n",
    "- **Фильтрация спама:** классификация электронных писем на \"спам\" и \"не спам\".\n",
    "- **Распознавание образов:** определение типа объекта на изображении (кот, собака, автомобиль и т.д.).\n",
    "\n",
    "> Задача классификации в контексте линейных моделей рассматривается в подробнее в [учебнике](https://education.yandex.ru/handbook/ml/article/linear-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../images/classification.png\" alt=\"Классификация\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Практический пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "dir(sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [2, 3]]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(multi_class='ovr', \n",
    "                                solver='lbfgs', \n",
    "                                max_iter=200)\n",
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                        np.arange(y_min, y_max, 0.01))\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "Z = classifier.predict(grid)\n",
    "Z = Z.reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Set1)\n",
    "plt.scatter(\n",
    "    X[:, 0], X[:, 1],\n",
    "    c=y, edgecolors='k', cmap=plt.cm.Set1,\n",
    "    s=40, linewidth=0.5\n",
    ")\n",
    "plt.xlabel('Petal length')\n",
    "plt.ylabel('Petal width')\n",
    "plt.title('Iris Classification with Logistic Regression')\n",
    "plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регрессия\n",
    "\n",
    "##### Суть задачи\n",
    "Регрессия направлена на предсказание непрерывной величины. Здесь модель изучает зависимость между входными признаками и непрерывным выходом, пытаясь минимизировать ошибку между предсказанными и истинными значениями.\n",
    "\n",
    "##### Постановка задачи\n",
    "Рассмотрим обучающую выборку вида:\n",
    "$$\n",
    "\\mathcal{D} = \\{ (\\mathbf{x}_i, y_i) \\}_{i=1}^N,\n",
    "$$\n",
    "где $\\mathbf{x}_i \\in \\mathbb{R}^d$ – вектор признаков, а $y_i \\in \\mathbb{R}$ – непрерывное значение, которое требуется предсказать (тоже может быть многомерным, $\\mathbb{R}^m$).\n",
    "\n",
    "Цель построить функцию $f: \\mathbb{R}^d \\to \\mathbb{R}$ (или $\\mathbb{R}^m$), так чтобы предсказания $\\hat y = f(\\mathbf{x})$ были как можно ближе к истинным $y$.\n",
    "\n",
    "##### Основные модели\n",
    "- **Линейная регрессия**\n",
    "- **Полиномиальная регрессия**\n",
    "- **Регуляризованная регрессия**\n",
    "- **Метод опорных векторов для регрессии (SVR)**\n",
    "- **Деревья решений и ансамбли**\n",
    "- **k-ближайших соседей (КNN)**\n",
    "- **Нейронные сети**\n",
    "\n",
    "##### Примеры\n",
    "- **Прогнозирование цен:** например, оценка рыночной стоимости недвижимости или прогнозирование цен акций.\n",
    "- **Физические прогнозы:** определение физических параметров системы по различным показателям.\n",
    "- **Временные ряды:** прогнозирование на основе исторических данных.\n",
    "\n",
    "> Задача регрессии в контексте линейных моделей рассматривается в подробнее в [учебнике](https://education.yandex.ru/handbook/ml/article/linear-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../images/regression.png\" alt=\"Регрессия\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Практический пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y, label='Data', s=30, edgecolors='k')\n",
    "sorted_idx = X[:, 0].argsort()\n",
    "plt.plot(\n",
    "    X[sorted_idx], y_pred[sorted_idx],\n",
    "    color='red', linewidth=2, label='Regression line'\n",
    ")\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Target')\n",
    "plt.title('Linear Regression Fit')\n",
    "plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кластеризация\n",
    "\n",
    "##### Суть задачи\n",
    "Кластеризация относится к методам обучения без учителя. Здесь задача состоит в **автоматическом разделении** набора неразмеченных объектов на группы (кластеры) по принципу максимального внутригруппового сходства и минимального межгруппового сходства. Кластеризация позволяет автоматически выявлять скрытые структуры и паттерны в данных.\n",
    "\n",
    "##### Постановка задачи\n",
    "Пусть имеется набор объектов без меток:\n",
    "$$\n",
    "\\mathcal{D} = \\{ \\mathbf{x}_i \\}_{i=1}^N, \\quad \\mathbf{x}_i \\in \\mathbb{R}^d.\n",
    "$$\n",
    "Задача кластеризации заключается в разделении объектов на $K$ групп, таких что объекты внутри одной группы максимально похожи друг на друга, а объекты разных групп – существенно различаются. При этом в части методов $K$ не задается наперед.\n",
    "\n",
    "Требуется найти функцию $g\\colon\\mathbb{R}^d\\to\\{1,2,\\dots,K\\}$, которая присваивает каждому объекту номер кластера, при этом для объектов одного кластера расстояния (или меры несхожести) между признаковыми векторами минимальны, а для объектов разных кластеров – максимальны. В ряде методов число кластеров $K$ задаётся заранее, в других оно определяется автоматически.\n",
    "\n",
    "##### Типы кластеризации\n",
    "- **Плоская (partitional):** сразу строится разбиение на заданное число $K$ кластеров.\n",
    "- **Иерархическая:** строится дерево вложенных кластеров.\n",
    "- **Плотностная:** кластеры определяются как области высокой плотности точек, число кластеров не задаётся заранее.\n",
    "- **Нечетная (fuzzy) кластеризация:** объект может частично принадлежать сразу нескольким кластерам.\n",
    "\n",
    "##### Основные модели\n",
    "- **k-means**\n",
    "- **Agglomerative Clustering**\n",
    "- **DBSCAN**\n",
    "- **Spectral Clustering**\n",
    "- **Gaussian Mixture Models (GMM)**\n",
    "\n",
    "##### Примеры\n",
    "- **Сегментация клиентов:** выделение групп потребителей с похожим поведением или интересами.\n",
    "- **Группировка документов:** автоматическое распределение текстов по темам.\n",
    "- **Обнаружение аномалий:** обнаружение выбросов или аномальных объектов в наборе данных.\n",
    "\n",
    "> Подробнее про методы и задачу кластеризации в целом можно прочитать в [учебнике](https://education.yandex.ru/handbook/ml/article/klasterizaciya)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../images/clustering.jpg\" alt=\"Кластеризация\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Практический пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_true = make_blobs(n_samples=300, centers=3, cluster_std=1.0,\n",
    "                       random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "y_kmeans = kmeans.fit_predict(X)\n",
    "centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(\n",
    "    X[:, 0], X[:, 1],\n",
    "    c=y_kmeans, s=60, cmap='viridis', edgecolors='k', alpha=0.8,\n",
    "    label='Clusters'\n",
    ")\n",
    "plt.scatter(\n",
    "    centers[:, 0], centers[:, 1],\n",
    "    c='red', s=250, marker='X', edgecolors='k', linewidth=1.5,\n",
    "    label='Centroids'\n",
    ")\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('KMeans Clustering')\n",
    "plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ранжирование\n",
    "\n",
    "##### Суть задачи\n",
    "Ранжирование применяется, когда требуется упорядочить объекты по степени их важности, релевантности или полезности. Например, при поиске в интернете алгоритмы ранжирования определяют порядок выдачи результатов на основе их соответствия запросу пользователя.\n",
    "\n",
    "##### Постановка задачи\n",
    "Пусть даны объекты $\\{\\mathbf{x}_i\\}_{i=1}^N$ и функция оценки важности (релевантности) $f(\\mathbf{x})$. Задача построить такую функцию $f: \\mathbb{R}^d \\to \\mathbb{R}$, чтобы при сортировке объектов по значениям $f(\\mathbf{x})$ наиболее релевантные объекты располагались выше.\n",
    "\n",
    "> Эта задача является частью систем поиска или рекомендаций, поэтому привести короткий наглядный пример тут, пожалуй, невозможно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Понижение размерности\n",
    "\n",
    "##### Суть задачи\n",
    "Понижение размерности применяется, когда данные имеют большое число признаков и требуется упростить их представление, уменьшая размерность пространства при сохранении важной структуры данных. Такой подход позволяет упростить визуализацию, ускорить вычисления и избавиться от избыточной информации.\n",
    "\n",
    "##### Постановка задачи\n",
    "Пусть исходные данные описываются в пространстве $\\mathbb{R}^d$ (где $d$ – большое число признаков). Необходимо найти отображение $g: \\mathbb{R}^d \\to \\mathbb{R}^k$ ($k < d$), такое что новые признаки сохраняют основную информативную структуру исходных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Практический пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3d, y_3d = make_blobs(\n",
    "    n_samples=300,\n",
    "    n_features=3,\n",
    "    centers=3,\n",
    "    random_state=42,\n",
    "    cluster_std=2.8\n",
    ")\n",
    "\n",
    "pca2 = PCA(n_components=2)\n",
    "X_2d = pca2.fit_transform(X_3d)\n",
    "\n",
    "pca1 = PCA(n_components=1)\n",
    "X_1d = pca1.fit_transform(X_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(19, 5))\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 1, projection='3d')\n",
    "scatter = ax.scatter(\n",
    "    X_3d[:, 0], X_3d[:, 1], X_3d[:, 2], \n",
    "    c=y_3d, s=50, cmap='viridis', edgecolors='k', alpha=0.8\n",
    ")\n",
    "ax.set_xlabel('Feature 1')\n",
    "ax.set_ylabel('Feature 2')\n",
    "ax.set_zlabel('Feature 3')\n",
    "\n",
    "axes[1].scatter(\n",
    "    X_2d[:, 0], X_2d[:, 1],\n",
    "    c=y_3d, s=50, cmap='viridis', edgecolors='k', alpha=0.8\n",
    ")\n",
    "axes[1].set_xlabel('PC1')\n",
    "axes[1].set_ylabel('PC2')\n",
    "axes[2].scatter(\n",
    "    X_1d[:, 0], [0]*len(X_1d),\n",
    "    c=y_3d, s=50, cmap='viridis', edgecolors='k', alpha=0.8\n",
    ")\n",
    "axes[2].set_xlabel('PC1')\n",
    "axes[2].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
